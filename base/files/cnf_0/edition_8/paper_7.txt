Nonlinear Magnification Fields
T. Alan Keaheyy



Edward L. Robertson

Department of Computer Science z
Indiana University

Abstract
We introduce nonlinear magnification fields as an abstract representation of nonlinear magnification, providing methods for converting
transformation routines to magnification fields and vice-versa. This
new representation provides ease of manipulation and power of expression. By removing the restrictions of explicit foci and allowing
precise specification of magnification values, we can achieve magnification effects which were not previously possible. Of particular
interest are the techniques we introduce for expressing complex and
subtle magnification effects through magnification brushing, and
allowing intrinsic properties of the data being visualized to create
data-driven magnifications.
CR Categories:
I.3.6 [Computing Methodologies]: Computer Graphics‚ÄîMethodology and Techniques I.3.8 [Computing
Methodologies]: Computer Graphics‚ÄîApplications H.5.2 [Information Systems]: Information Interfaces and Presentation‚ÄîUser
Interfaces;
Keywords: information visualization, nonlinear magnification,
data-driven magnification, fisheye views, magnification brushing,
data-mining

1 Introduction
Many approaches have been described in the literature for stretching and distorting spaces to produce effective visualizations of data.
Such techniques have been called polyfocal projection [6], bifocal
display [20], fisheye views [3, 18], multi-viewpoint perspective display [14], rubber sheet [19], distortion-oriented presentation [12],
focus + context [11] and many other terms [16, 1, 15, 5]. In [9, 10]
we introduced the term nonlinear magnification to describe the effects common to all of these systems. The basic characteristics of
nonlinear magnification are non-occluding in-place magnification
which preserves a view of the global context. During our research
on the work described in [9, 10] there were a number of issues
which we encountered. A brief discussion of some of these issues
will provide context and motivation for the results presented in the
remainder of this paper.
The focus of our work in [9, 10] was to define a nonlinear
magnification system using simple modular components joined together to create complex magnification effects. In doing this, we
 http://www.cs.indiana.edu/hyplan/tkeahey/research/nlm/nlm.html
y This work was supported by US Department of Education Award #

P200A502367.
z Department of Computer Science, 215 Lindley Hall, Indiana University, Bloomington, IN 47405 ftkeahey,edrbtsng@cs.indiana.edu

distinguished between linear and nonlinear magnification transformations and illustrated how the best properties of each could be
exploited by providing simple methods to combine these within a
single transformation, and by introducing constrained transformation domains which remain invariant even when the magnification
or compression changes. We also introduced the distinction between continuous and discrete domains to describe the effectiveness of these operations for varying tasks such as nonlinear image
magnification[8] and graph visualization.
We described two different ways for using piecewise linear functions for nonlinear magnification transformations. First we extended the work on piecewise functions in [12, 19], creating 1D
piecewise linear transformations as efficient and expressive alternatives to the more conventional continuous 1D transformation functions which form the basis for higher-dimensional transformations.
Then we introduced 2D piecewise linear transformations which
provide approximations to complex sequences of transformations.
We discussed how these piecewise functions could be manipulated
directly to create custom magnification effects. For 1D piecewise functions, we described how they could be easily manipulated
through changes to either the magnification or transformation function. We then raised the question of how such manipulations could
be performed on 2D or higher-dimensional piecewise linear transformations. This paper will provide answers to that question.
Although our system for nonlinear magnification transformations was successful in reducing complex magnification effects to
a set of easy to understand and implement operations, there are a
number of general properties which our modular system still shares
with existing nonlinear magnification systems. These issues have
lead us to look for a more general schema for defining and implementing nonlinear magnification systems.
The first major limitation of the existing nonlinear magnification
systems could be referred to as the ‚Äútyranny of the foci‚Äù. Although
explicit centers of magnification are clearly desirable in many cases,
this also puts severe limitations on the types of magnification and
interaction which can be produced. Interaction becomes an exercise
in manipulation of discrete magnifying ‚Äúlenses‚Äù, and additional expressiveness of magnification comes primarily through the addition
of more and/or complex lenses, thus increasing the computational
complexity of computing the overall transformation.
The second difficulty encountered with existing systems for nonlinear magnification involves determining the overall effect of complex transformations. A general purpose mechanism would be useful to determine the effects of complex transformations with multiple foci, so that the global effect of the transformations can be
determined across the entire space of a domain, rather than just at
the centers of magnification or other discrete points.
A third issue involves the degree of difficulty associated with
defining complex transformations, through both programming and

user interfaces. Although current nonlinear magnification systems
are able to express useful foci-based transformations, we plan to illustrate in this paper an alternate method which allows for simple
and direct specification of much more sophisticated magnification
effects. Examples of the kinds of expressiveness that are difficult or
impossible to achieve with existing systems include: inverse transformations, arbitrary excluded and constrained domains of magnification, locking regions at fixed magnification levels, and direct
specification of magnification values over the entire domain.
In this paper we will develop further a theory of nonlinear magnification that addresses many of these issues. In particular, we reduce the concept of nonlinear magnification to a field of scalar magnification values. Broadly speaking, these nonlinear magnification
fields provide benefits at two levels. First, they serve as a basis for
realizing the effects of existing techniques, even though their underlying mechanisms may be very different. Second, they directly
define space transforming visualizations and can be operated on
in computationally efficient and conceptually effective ways, thus
yielding powerful visualization tools.
Expressing magnification as a field of arbitrary scalar values provides a much greater expressiveness of magnification and ease of
manipulation than is possible using other techniques. By removing
the restrictions of discrete foci we allow fluidly shifting magnifications of arbitrary complexity, and can factor out magnification
complexity from the time required to compute suitable transformation functions so that computation is independent of the complexity of the magnification function. We will describe a number of
novel ways in which the flexibility of these nonlinear magnification
fields can be used to create effective visualizations. The techniques
presented range from low-level precise specification of magnification, through the creation of expressive user-interface techniques,
to sophisticated magnification fields which can be constructed by
application programs.
In brief, the work described in this paper makes the following
major contributions:

introduces a general method for converting complex transformations of two or more dimensions to scalar magnification
fields, thus allowing consistent mappings between complex
transformation and magnification functions
introduces an iterative method for converting scalar magnification fields to transformations, thus removing dependence on
explicit foci for defining nonlinear magnifications, and facilitating simple and direct methods for specifying bounded and
excluded regions of magnification
introduces magnification brushing as an user-interface technique allowing creation of complex and subtle magnification
effects
introduces data-driven magnification as a technique which allows properties of the data to directly define magnifications
for viewing that same data

2 Magnification Fields
When describing nonlinear magnification systems, it is useful to
distinguish between magnification and transformation functions,

as first described in [12]. The transformation function directly
stretches and compresses the space, while the magnification function (which is the derivative of the transformation function) represents the magnification values which are implicit in the transformation function. Converting between magnification and transformation functions in one dimension is a relatively straightforward task,
however the situation is much more complicated in two or more
dimensions. In the remainder of this section we will describe techniques for accomplishing these conversions, after introducing some
basic notation.1
Any magnification employs a transformation function t
(x0 y 0  = tx y ) which moves points of a rectangular domain
D within a frame. Since we want the magnification to be nonoccluding, we require that t is at least C 0 continuous and orderpreserving (given x01 y10  = tx1 y1  and x02 y20  = tx2 y2 ,
x1 x2 implies x01 x02 , and similarly for y). For computational purposes, we deal with t only on a p  q integer grid G , with
g : G ! D (g maps the regular grid G over the domain D), and
represent a discrete approximation of t with a quadrilateral grid T
(T = t g , where ‚Äô ‚Äô represents composition).
A magnification field m is a 2D scalar field of the form z =
mx y which gives the regional expansion around a point. As
with t, m is represented on G by a quadrilateral mesh M (M =
m g). A transformation t corresponds to a magnification m, where
mx y = @tx y=@x  @tx y=@y. This is approximated
using an area-based function mc which computes the local magnification for each node in T . For computational efficiency, the area-

based magnification we use actually corresponds to the square of
the linear ‚Äúpower‚Äù sometimes used in describing lenses. In describing computations with magnifications and transformations, notation
such as mc or TC indicate variations of these functions or their approximations.

2.1

Transformation Grid

! Magnification Field

Conversion from a given transformation grid T to a magnification
mesh M involves numerically computing an approximate derivative
of T . The computation begins with an area function a which, for
each node in T , returns an approximation of the area defined by the
neighbouring nodes. One possibility for this function simply uses
the convex hull of the 4-connected neighbours fT i + 1 j  T i ,
1 j  T i j +1 T i j , 1g. We define Ca to be the constant area
associated with any T i j  in the untransformed uniform sampling
grid. The approximate magnification value for a point T i j  is
then given by M i j  = mc i j  = ai j =Ca . More accurate
area calculations are possible, such as explicitly finding the area
of the four surrounding cells. In practice however, we find that
this increase in accuracy does not significantly change the results.
Coarser approximations are adequate, as long as the area metric is
used consistently throughout the system. Figure 1 shows an example of a transformation and its associated magnification mesh
calculated with this method.
This technique allows any nonlinear magnification system to create a landscape representation of its implicit magnification with
elevation-based shading. The surfaces described in 3DPS [2] may
appear to be similar to this landscape representation, however closer
inspection reveals that the two systems have fundamental differ1 Although this paper presents results in 2 dimensions, we note that the
view-independent nature of the techniques presented here allows for trivial
extension to 3 or more dimensions.

Figure 1: Transformation and Magnification

ences. The most significant difference is that elevation and magnification do not correspond directly in 3DPS; the view-dependent
nature of 3DPS means that magnification is also dependent on the
degree of orthogonality of the surface normal to the viewing vector.
The inconsistent relation between elevation and magnification is
readily apparent when considering that with 3DPS both compressed
and expanded areas will have a higher elevation than undistorted areas of unit magnification. This points to another difference between
the two systems: the way that they produce shading. 3DPS shades
regions of distortion using a computationally expensive 3D lighting
model, whereas the system we present here shades regions of magnification simply by mapping elevation values into a color/intensity
ramp.
Figure 2 shows another example illustrating multiple bounded
regions and linear magnification; the transformation grid was generated using the techniques described in [10]. As a further example
of how these techniques can be used to determine the implicit magnification generated by existing systems, we use the example of
Perspective Wall [13], which is representative of the class of nonlinear magnification systems that are based on a perspective projection of 3D surfaces (other examples include [17, 2]). By sampling
a perspective wall transformation function with a regular grid, we
obtain a transformation grid which is used to generate the associated magnification mesh (see Figure 3). These examples show how
transformation and magnification functions can now be tightly coupled across entire domains even for complex transformations.

Figure 2: Multiple/Bounded/Linear Regions of Magnification

2.2 Magnification Field

! Transformation Grid

While it is a relatively straightforward task to find the implicit magnification mesh M associated with a transformation grid T by computing the approximate derivative; it is a much more complex task
to construct a suitable transformation grid given a magnification

Figure 3: Perspective Wall Magnification

mesh. Simple perspective projections of these meshes are not effective because they may introduce problems of occlusion as shown in
Figure 4, which shows a perspective projection of the magnification
field in Figure 2.

Figure 4: Occlusion from Perspective Projection
In general terms, we want to integrate the magnification mesh
values in order to construct an order-preserving transformation grid.
There are a number of issues which make this a difficult task. The
most fundamental problem involves finding a meaningful way to
convert a single magnification value into a two coordinate x y 
transformation; there are usually many transformations possible for
a given magnification. We have investigated and developed direct
methods to solve this problem, but have found these methods to be
unsuited to the specific task of generating nonlinear magnification
transformations. Some of the major problems which we have observed with the direct approaches are: 1) bounded regions of magnification in M should produce bounded regions of transformation in
T to preserve a static context, 2) the transformation should be symmetric and centered around magnification maxima, and not constructed relative to some arbitrary boundary of the domain, and 3)
solutions providing only correct area in T do not preserve desired
visual properties of the magnification, such as scale and aspect ratio
within regions of linear magnification.
In order to address these problems we have developed an iterative method which provides a numerical solution to the integration
problem. By dealing with a localized basis for computation, we are
able to simply and directly control the overall behaviour of the algorithm to produce the desired final result. The general problem is
to compute an approximate transformation grid TC from a specified magnification mesh MS . The key to our approach is that the
ease of converting from transformation to magnification facilitates
the conversion in the opposite direction. We compute the magnification MC from the transformation TC , and then the magnification
error ME = MS
MC . We then use ME to further refine the
approximation TC .

,

To enhance the visualization of the performance of our method,
we join the z magnification values of MC to the x y  coordinates
of TC to create a composite mesh MCv . We similarly join the ME
values to TC giving MEv . MCv and MEv are used for visualization
only, and are not used in any internal calculations.
Conceptually, our algorithm is straightforward. We initialize TC
to the identity transformation. For each iteration, we compute ME
on a node-by-node basis. If ME i j  0 then we push the neighbours of TC i j  away a little bit from TC i j . Conversely if
ME i j 
0 then we pull the neighbours of TC i j  a little bit
closer to TC i j . Both the pushing and pulling operations are easily constrained to preserve the ordering of nodes in TC . Figure 5
shows an example of the operation of this algorithm over a few iterations (using MS from Figure 1); and Figure 6 shows how our
method handles the multiple, bounded and linear regions of magnification specified in Figure 2. There are a number of parameters
and issues to explore in this algorithm, which we discuss below.

the amount of error that is applied to neighbouring nodes. When
Cr = 0 no displacement occurs, whereas Cr = 1 causes the algorithm to attempt as much displacement as possible on each step
of the iteration while still preserving ordering. To an extent, higher
values of Cr cause the system to converge faster, but if Cr is too
high the approximation will tend to thrash and possibly not converge at all. We typically use Cr = 0:3.
The local error ME i j  can be distributed evenly over the
neighbouring nodes, however the algorithm converges faster if we
weight the displacements based on the distances between a node
and its neighbours. If ME i j  0, we weight the displacements
so that closer neighbours are pushed a greater distance than farther
neighbours. Similarly for ME i j 
0, we weight the displacements to pull more distant neighbours a greater distance than closer
neighbours.
Our algorithm converges independent of the complexity of the
magnification field, where convergence is measured by root mean
squared error:
RMSE =

Figure 5: TC , MCv and MEv on Iteration 1,40,80

vuXp Xq
ut
i=1 j =1

E i

M

2

j

The primary determining factor of convergence speed is the volume
of specified magnification, or more precisely the volume of error in
ME . There are a number of parameters which we can use to tune
the performance of our algorithm based on speed/accuracy tradeoffs. First we create an error clipping constant Ce with a default
value of 0, then our algorithm ignores nodes where ME i j  Ce .
This causes it to converge faster because it does not have to compress areas whose implicit magnification is greater than its specified
magnification. The result of this is that regions of demagnification are not strictly enforced, but allowed to remain at their original unmagnified level (excepting where magnified regions push into
those demagnified regions). This allows the resulting transformation grid to fill up the available space more efficiently, eliminating
dead screen regions which were outside the range of the original
transformation grid. Color Plate A shows a few iterations on an
input identical to that used for Figure 5, except that error clipping
with Ce = 0 is used on the color plate. When this error clipping
method is used, we redefine our error measure as:

vuuX X
t
p

RMSE =

q

i=1 j =1

M ax0 M

E i

j

,

e2

C

and observe that the primary determining factor of speed of convergence is now the volume of ME above the clipping plane defined
by Ce. By increasing Ce to 0:1 or 0:25, little visual difference
is apparent in the resulting TC , although substantial performance
benefits occur.

Figure 6:

M

Cv and TC Computed from Figure 2

As mentioned previously, many different area metrics can be
used in these methods. The area metric used will determine which
neighbours should be displaced in our algorithm (i.e. if the area
metric is 4-connected, then the algorithm should only displace
the 4-connected neighbours). The algorithm converges faster if
we multiply the error ME i j  by the specified magnification
MS i j , so that regions of higher magnification will be more
strongly weighted. We also use a refinement coefficient Cr to scale

In a similar fashion we can define a magnification clipping constant Cm , and make our algorithm ignore nodes having MS i j 
Cm . Depending on the particular MS being used, increasing Cm to
0:5 or 0:75 can significantly increase performance with little cost in
the final visual result. Error clipping is more robust than magnification clipping however, because it takes into account the changes to
the implicit magnification of TC as the algorithm progresses, and
thus distributes the magnification more evenly over the entire domain. By carefully adjusting Cm and Ce for the particular application, very significant increases in performance can be achieved, to
the point where our algorithm converges at speeds which are suitable even for interactive applications requiring high frame-rates.

Mesh resolution is also a significant factor in the performance of
our algorithm. High resolution meshes are able to compute finer
detail than lower resolution meshes, but generally require greater
computation time. Thus mesh resolution is another parameter in
our systems which can be used to tune results. Table 1 summarizes
the effect of adjusting these parameters 2 .

pq

32  32

Cm

-

0.75

24  24

0.75

Ce

0.00
0.25
0.00
0.25
0.00
0.25
0.00
0.25

Iterations
154
72
50
73
72
50
98
40
28
40
40
28

3

Time (s)
0.826
0.236
0.104
0.220
0.198
0.072
0.298
0.072
0.030
0.068
0.058
0.022

Table 1: Performance Using MS from Figure 1

2.3 Degenerate Field Specifications
Not all possible magnification specifications will have a solution,
there are some degenerate specifications which are physically impossible to satisfy without violating the desired characteristics for
nonlinear magnification. Although these physically degenerate
cases have no exact solution, our algorithm still manages to compute a reasonable compromise for them. We describe the degenerate cases below, along with how they can be effectively dealt with.
First however we point out that any magnification field which is
generated from a transformation meeting our stated requirements
for nonlinear magnification will (by definition) never be degenerate,
and our iterative method can always manage to construct a transformation grid having the same implicit magnification field as the
original transformation grid.
The first type of degenerate case occurs when the volume defined
by those points in MS which pass the error and magnification clipping tests exceeds the volume of a uniform identity magnification
over the region defined by those points in MS that pass the magnification clipping test. For example a mesh specifying 2 magnification across the entire field cannot possibly be satisfied while
maintaining the desired properties of non-occluding in-place magnification. This reflects the intuitive notion that every expansion
must cause a corresponding compression at some other region. Another related type of degenerate case involves conflicting regions
of magnification. For example when a region of very low magnification is surrounded by regions of high magnification (a doughnut
shape), it may be physically impossible to satisfy both specifications simultaneously.



We can resolve these degenerate cases by making the assumption that regions of high magnification (and high error) should take
higher priority. In this way Ce and Cm can always be adjusted so as
to relax the specification to a non-degenerate configuration. In addition, weighting ME by MS (as described previously) will resolve
degeneracies above the clipping planes by emphasizing higher magnification values. It is worth noting that we can also emphasize ar2 Timings

were obtained on a 195 MHz MIPS R10000 CPU.

eas of demagnification simply by reversing the clipping tests and
weighting by the inverse of the magnification.

Magnification Field Manipulation

By isolating magnification field specification from the transformation function, it is now possible to manipulate the magnification
values directly rather than have them change only as a side effect
of changes in the transformation. We refer to systems which rely
on the side-effects of transformation functions to produce nonlinear magnification as transformation-based systems. Another class
of systems use a physical viewing model and perspective projections to produce nonlinear magnification effects [13, 17, 2]. Such
perspective-based systems have an irregular correspondence between elevation and magnification, and require careful attention
to the orthogonality of surface normals to the view vector, thus
adding additional degrees of complexity to the magnification specification task. In contrast, the system we present here is a true
magnification-based system. Direct manipulation of the magnification mesh makes for a system which is both simpler and more expressive than previous nonlinear magnification systems. From the
user and application standpoint, the task now is simply to specify
desired magnification levels in a scalar field. The conversion techniques in Section 2.2 automate the task of constructing a transformation grid having those magnification values (assuming the case
is not degenerate, and that such a transformation grid is possible).
This frees the user and application program from the often difficult task of determining what combination of complexly interacting transformation functions or surface normals will produce the
desired magnification.
The remainder of this section will highlight some of the ways
in which direct magnification field manipulation can be used, from
low-level node operations to high-level global constructions. In all
of these examples, we begin with a direct magnification specification and end with a transformation reflecting that specification. We
intend to illustrate through these examples that ‚Äúmagnification‚Äù is a
more intuitive and useful interface concept than ‚Äúdistortion‚Äù. Distortion is not the goal of our system but only a by-product, although
our system does allow for explicit representation of the distortion
present in any nonlinear magnification field. Defined as the rate of
change in magnification, distortion is easily computed as the gradient of the magnification field, as shown in Figure 7 and Color
Plate B. This clearly reveals the derivative nature of distortion in
nonlinear magnification systems.

Figure 7: Magnification and Distortion from Figure 2

3.1 Node-Level Specification
At the lowest level, we can control the magnification mesh on a
node by node basis. For demonstration purposes, we have created a
simple interface which allows the user to select single nodes or rectangular regions of nodes from the magnification mesh. The magnification levels associated with these selected nodes can then be
raised or lowered accordingly. This provides us with a very finegrained control of the magnification specification. Of greater interest is the ability to associate logical values with the selected nodes.
For example the ability to ‚Äúlock‚Äù nodes in place allows for specification of regions which will remain unchanged in the transformation grid. This allows any region of the domain to be excluded
from the transformations, as shown in Figure 8; these regions can
also be locked at magnification levels other than unity by transforming them before locking them in place. In addition, it now
becomes a trivial matter to constrain the transformation to any arbitrary bounded domain (including concave domains) simply by locking those nodes which define that bounded domain (see Figure 8).
Some of the examples in this paper used locked nodes on the mesh
perimeter to ensure that the transformed grid would still fit precisely
in the original rectangular sampling area.
A major feature of this locking mechanism is that in many
cases specifying bounded regions of magnification (or nonmagnification) actually reduces the computation required (assuming degenerate cases are not introduced). Thus while these bounded
regions are similar to the constrained domains which we introduced
in [9, 10]3 , and the global bounding-box constraints described in
[19], they differ in that additional computation or program complexity is not required here to enforce the fixed boundaries. This
locking mechanism allows us to obtain arbitrary bounded and excluded regions for ‚Äúless than nothing‚Äù in computational cost in most
cases, by means of a trivial boolean flag check for each node in the
iterative conversion process.

Figure 8: Node-Locking Excluded and Bounded Domains

3.2 Mesh-Level Operations
Our representation of magnification as a simple scalar field greatly
facilitates many operations which would be very involved (if not
impossible) with non-magnification-based systems. Given a transformation grid T having an implicit magnification mesh M , it is
a simple matter to compute the inverse mesh M ,1 , and then find
the inverse transformation T ,1 (see Figure 9). Further, although
our system allows for multiple regions of magnification within a
3 The ‚Äúdistortion control‚Äù presented in [2] is not equivalent to these, as it
does not provide invariant boundaries that are independent of the magnification/distortion parameters.

single mesh, it is also possible to combine multiple meshes in useful ways using simple node-by-node operations across the meshes.
As examples, two meshes can be blended with proportional averaging: M i j  = dMa i j  + 1 dMb i j  0
d
1,
combined: M i j  =Max Ma i j  Mb i j , or composed:
M i j  = Ma i j 
Mb i j . In addition to operations on the
magnification values across the meshes, it is also possible to perform operations on logical mesh values (such as the node-locking
mechanism described in the previous subsection). For example we
can find the intersection of the non-locked regions of magnification
between two meshes simply by AND-ing their logical values.

,

 



Figure 9: Inverse of Figure 1 M ,1 and T ,1

3.3

User Interfaces

The expressiveness and implementation-independent nature of our
representation makes it well suited for the construction of userinterfaces which employ nonlinear magnification. By developing
a nonlinear magnification interface as an abstraction layered above
our magnification field specification, the designer can construct
magnification tools and techniques which are customized to specific tasks.
We have just begun to explore the possibilities of layering interfaces on top of our general magnification field techniques. Perhaps
the simplest interface involves construction of a discrete ‚Äúmagnifying glass‚Äù which can be moved over the domain; other possibilities are more interesting. For example, by making the magnification field MS persistent outside of that same magnifying glass, the
user can effectively ‚Äúpaint‚Äù arbitrary regions of magnification by
stroking the glass (which might now better be described as a brush)
over the domain. By using the brush to increment the magnification rather than to set the absolute magnification value, stroking a
region with the brush would correspond to painting the region with
increasing levels of magnification (see Figure 10 and Color Plate
C). By using persistence which decays over time (or by not resetting TC after each movement of the magnifying glass, since TC
will carry some residual implicit magnification from previous iterations), we obtain ‚Äútrails‚Äù of magnification which gradually fade
out behind the magnifying glass (see Figure 10). This degree of
expressiveness goes far beyond anything that can be achieved with
existing systems, and moves magnification towards a commodity
user-interface item, similar to color and intensity.

3.4

Data-Driven Magnification

Visualization is but one technique applicable to the exploration of
large databases (so-called ‚Äúdata mining‚Äù). The greatest potential

simple example where more work may be required is the shape of
the magnified regions. While our iterative method can smooth the
boundaries of a ‚Äúgerrymandered‚Äù magnification mesh, the resulting
region may still clash with the viewer‚Äôs intuition or esthetics.

4

Figure 10: Magnifying Brush and Trail
benefit will combine higher-level (database and semantic-related)
mechanisms with low-level (rendering or presentation) ones that
are the primary focus of this paper. The most significant bridge
between these levels is to use the data to control presentation, and
controlling magnification is a major component of this.
One major reason for implementing transformations based on an
arbitrary magnification field is to allow properties of the data itself
to specify the magnification. When the magnification is entirely directed by human commands, it is only possible to provide a small
number of magnification ‚Äúlenses‚Äù which can be easily applied to an
image. But much more extensive mapping mechanisms are required
when magnification is data-driven, since the regions of magnification may potentially have arbitrary shapes.
Using data to indicate regions of special importance is a familiar
idea; color coded contour maps display things as concrete as altitude and as intangible as political attitude. For a contour map of
environmental pollution, the next step beyond displaying pollution
‚Äúhot spots‚Äù is to expand those regions in order to show the pollution sources within those regions. The exploration of hot-spots for
pollution sources can be done by a user-controlled lens, because
the situation is static and the task requires only sequential attention to individual hot spots. Automatic magnification becomes truly
significant when the information is dynamic or the user‚Äôs attention
must encompass the entire scope at once. An application that displays both of these characteristics is air traffic control. Figure 11
and Color Plate D show a simulated air traffic control system where
regions of higher traffic density are automatically magnified 4 .

Leung and Apperley [12] provide a comprehensive review and taxonomy of major nonlinear magnification systems. Through the introduction of the distinct concepts of transformation and magnification functions, they describe the basic one dimensional properties
of nonlinear magnification systems in a systematic fashion. For two
dimensions, they use the metaphor of a rubber sheet to describe
the behaviour of nonlinear magnification systems in broad terms.
Although useful for conceptualization, this metaphor is not rigorous enough to directly serve as the basis for a constructive theory.
One of the goals of the current paper is to provide a more rigorous treatment of some of the issues which they raise, in particular
the non-trivial magnification to transformation conversion for more
than one dimension.
Space-scale diagrams [4] are well suited for dealing with typical pan-and-zoom systems; however such systems do not share
basic properties of nonlinear magnification systems, such as preserving a view of the global context. The view-dependent nature of
space-scale diagrams makes them unsuitable for describing nonlinear magnification systems, as the lines of sight (‚Äúgreat rays‚Äù) which
they use may introduce problems of occlusion for 1D functions
having more than one maxima. These problems are compounded
further for 2D, and issues of converting magnifications to transformations (and vice-versa) are not addressed in this work.
We have already described significant differences between 3DPS
[2] and our system in Section 2.1. In addition, 3DPS uses explicit
foci to define the magnification, so that increasing complexity of
the magnification function entails additional computation. With
3DPS non-occlusion and confinement of data to fixed regions is
not inherent, and requires additional (unspecified) constraints on
parameters, whereas by its very nature our iterative system guarantees non-occlusion and confinement to any size or shape of domain.
Also worth noting is that 3DPS is a perspective-based system which
is closely tied to its own specific implementation of a physical viewing model. In comparison our system is less implementation dependent, and the concepts and techniques can be directly applied to a
broad range of visualization and nonlinear magnification systems.

5

Figure 11: Data-Driven Magnification
Our efforts so far are a mere beginning of dealing with datadriven magnifications. In particular, these efforts are aimed at providing tools necessary for study of the human interaction factors involved, but not at conducting those human factors experiments. A
4 The

authors (who fly frequently) would suggest further human-factors
studies be carried out before this technique is tried in actual control towers.

Related Work

Conclusions

Nonlinear magnification fields provide a natural representation for
dealing with nonlinear magnification systems. We have shown how
the magnification effects of other continuous nonlinear magnification systems can be examined and compared by constructing implicit magnification fields from their transformations, providing a
consistent mapping between complex transformation and magnification functions. Going in the other direction, the iterative method
which we present allows construction of a transformation from an
arbitrary magnification field specification. Our method is simple
and effective, even on complex fields having multiple maxima,
bounded regions, and areas of linear magnification. A number of
parameters can be easily tuned to control overall performance.

Our abstract magnification field representation is expressive and
easy to manipulate. By removing the restrictions of view dependence and explicit foci, our system provides a natural and intuitive
means of specifying magnification which does not rely on the side
effects of complexly interacting transformation functions or surface
normals. This ease of manipulation can be exploited on a number
of levels, from fine-grained control at the individual node level to
sophisticated user-interface techniques which can be layered on top
of our system. Of particular interest is the ability to use properties
of the data itself to define the magnification fields best suited to visualizing that data, thus opening the door to many new applications
of nonlinear magnification.

6 Further Work
We are investigating the use of multi-resolution methods to increase
the speed and interactivity of our iterative method. More work is
also being done on providing effective interfaces to our low-level
routines in a way which takes advantage of the power and flexibility
of this system. This work is proceeding on two levels: constructing user interfaces for interactive application, and exploring further
how properties of data can best be used to create data-driven magnifications.
We envision a whole range of applications which can use the
techniques presented here to advantage. In addition to the obvious possibilities presented by data-driven magnification (such as
data-exploration and data-mining), any visualization task requiring attention to fluidly shifting features should be able to benefit
from the application of our techniques. Another set of suitable applications becomes apparent when considering the ways in which
implicit magnification fields can be used to drive other aspects of
visualization. We are looking forward to presenting results from
these application areas in the near future.

References
[1] Benjamin B. Bederson and James D. Hollan. Pad++: A
zooming graphical interface for exploring alternate interface
physics. In Proceedings of the ACM Symposium on User Interface Software and Technology, 1994.
[2] M.S.T. Carpendale, D. Cowperthwaite, and D. Fracchia. 3D
pliable surfaces: For the effective presentation of visual information. In Proceedings of the ACM Symposium on User
Interface Software and Technology, pages 217‚Äì226, 1995.
[3] George W. Furnas. Generalized fisheye views. Human Factors in Computing Systems, CHI ‚Äô86, pages 16‚Äì23, April
1986.
[4] George W. Furnas and Benjamin B. Bederson. Space-scale
diagrams: Understanding multiscale interfaces. In Proceedings of the ACM Conference on Computer Human Interaction,
1995.
[5] Volkmar Hovestadt, Oliver Gramberg, and Oliver Duessen.
Hyperbolic user interfaces for computer aided architectural
design. In Proceedings of the ACM Conference on Computer
Human Interaction, 1995. Short paper.

[6] Naftali Kadmon and Eli Shlomi. A polyfocal projection for
statistical surfaces. The Cartographic Journal, 15(1):36‚Äì41,
June 1978.
[7] T. Alan Keahey.
the Nonlinear Magnification
Home Page.
A WWW resource devoted to all
aspects of nonlinear magnification available at:
www.cs.indiana.edu/hyplan/tkeahey/research/nlm/nlm.html.
[8] T. Alan Keahey and Edward L. Robertson. Non-linear image
magnification. Technical Report 460, Department of Computer Science, Indiana University, April 1996.
[9] T. Alan Keahey and Edward L. Robertson. Techniques for
non-linear magnification transformations. Technical Report
455, Department of Computer Science, Indiana University,
March 1996. Draft submission of InfoVis‚Äô96 paper.
[10] T. Alan Keahey and Edward L. Robertson. Techniques for
non-linear magnification transformations. In Proceedings of
the IEEE Symposium on Information Visualization, IEEE Visualization, pages 38‚Äì45, October 1996.
[11] John Lamping, Ramana Rao, and Peter Pirolli. A focus+context technique based on hyperbolic geometry for visualizing large hierarchies. In Proceedings of the ACM Conference on Computer Human Interaction, 1995.
[12] Y.K. Leung and M.D. Apperley. A review and taxonomy of
distortion-oriented presentation techniques. ACM Transactions on Computer-Human Interaction, 1(2):126‚Äì160, 1994.
[13] J.D. Mackinlay, G.G. Robertson, and S.K. Card. The perspective wall: Detail and context smoothly integrated. In Proceedings of the ACM Conference on Computer Human Interaction,
pages 173‚Äì179, 1991.
[14] Kazuo Misue and Kozo Sugiyama. Multi-viewpoint perspective display methods: Formulation and application to compound graphs. In Human Aspects in Computing: Design
and Use of Interactive Systems and Information Management,
pages 834 ‚Äì 838. Elsevier Science Publishers, 1991.
[15] Emanuel G. Noik. A space of presentation emphasis techniques for visualizing graphs. In Proceedings of Graphics
Interface, pages 225‚Äì234, May 1994.
[16] Mark Phillips and Charles Gunn. Visualizing hyperbolic
space: Unusual uses of 4x4 matrices. In Proceedings of
the 1992 Symposium on Interactive 3D Graphics, ACM SIGGRAPH, March 1992.
[17] G. Robertson and J. D. Mackinlay. The document lens. In
Proceedings of the ACM Symposium on User Interface Software and Technology, pages 101‚Äì108, 1993.
[18] Manojit Sarkar and Marc H. Brown. Graphical fisheye views.
Communications of the ACM, 37(12):73‚Äì84, 1994.
[19] Manojit Sarkar, Scott S. Snibbe, Oren Tversky, and Steven P.
Reiss. Stretching the rubber sheet: A metaphor for visualizing
large layouts on small screens. In Proceedings of the ACM
Symposium on User Interface Software and Technology, 1993.
[20] Robert Spence and Mark Apperley. Data-base navigation: An
office environment for the professional. Behaviour and Information Technology, 1(1):43‚Äì54, 1982.

Magnification

Transformation

Distortion
Plate A:
Convergence with error clipping
Iteration 1, 40, 80 ( TC , MCv , MEv )

Plate C:
Magnification Brushing

Plate B:
Relation of transformation, magnification and
distortion

Plate D:
Data‚àíDriven Magnification

