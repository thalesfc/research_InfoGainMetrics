3D Head Models Retrieval Based on Geometrical Measurement for Modeling
Mandun Zhang, Xiangyong Zeng, Peng Lu, Yangsheng Wang
Institute of Automation, Chinese Academy of Sciences, 100080, China
{mdzhang, xyzeng, plu, wys}@mail.pattek.com.cn

Abstract
In this paper, we present a 3D head models
retrieval algorithm based on geometrical measurement
for modeling. The proposed method mainly has two
steps. Firstly we create a dataset of generic models
and gain their feature points which are used to identify
horizontal and vertical proportions. After extraction of
individual frontal facial feature points, the most
similar generic model can be chosen according to
similarity criterion. Secondly these feature points are
devoted to deform the chosen generic model with
corresponding feature points using Radial Basis
functions (RBF), and texture mapping makes it more
realistic. The experiment results demonstrate that our
new algorithm can retrieve the most similar model to
reduce deformation error and photo- realistically
render 3D face.

1. Introduction
From the viewpoint of both computer vision and
computer graphics, fast 3D facial modeling and
animation is one of most challenging and interesting
research topics. And facial animation has been applied
in human-computer interfaces, interactive games,
multimedia titles, VR, and, as always, in a broad
variety of animations production.
The procedure of the facial modeling and animation
can be summarized as follows: 1) a structural generic
model selection, 2) a specific face information based
on computer vision or based on image acquirement, 3)
the generic model deformation, and 4) texture mapping.
Many research efforts have been made to generate
realistic facial modeling from a generic model [1, 2, 3,
4]. But how to choose a generic model hasn‚Äôt come
true. It involve in the head model retrieval.
Geometrical measurement method is initial and
simple, but also efficient for face recognition. Lee [6]
and Zhou [5] proposed a face recognition method
using the geometrical features. Firstly facial feature

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV‚Äô05)
0-7695-2392-7/05 $20.00 ¬© 2005 IEEE

points are extraction. Then important features are
extracted using feature points. These features include
distance, area and angle on the nose, mouth, eyes, etc.
Yeunghak extracted 12 features and Zhou extracted 11
features. Starovoitov [7] used 37 feature points.
Segments, perimeters and areas of some figures
formed by the detected points, may present geometric
features.
Horace [8] presented a technique for 3D head
models retrieval. His approach combined a 3D shape
representation scheme and hierarchical indexing of 3D
models based on facial region similarity. His proposed
shape similarity measurement is based on comparing
3D model shape signatures computed from the
Extended Gaussian Images of polygon normal.
The methods mentioned above are about 3D head
shapes matching. But in this paper we only know the
2D shape information of the performer. So what we
will adopt is different from above.
In this paper, we advance a practical 3D head
retrieval approach based on geometrical measurement
for an individual facial modeling. Firstly a dataset of
generic models is created and their feature points are
gained. Following work is to identify horizontal and
vertical proportions using these feature points. After
individual frontal facial feature points are extracted,
the most similar generic model is identified. Then
these feature points are devoted to deform the chosen
generic model with corresponding feature points using
RBF. Finally texture mapping is performed for realistic
modeling. The rest of this paper is organized as
follows. Section 2 describes how to create the dataset
of generic models. Section 3 describes our geometrical
measurements method. Section 4 gives how to choose
a similar generic model. Section 5 describes
deformation algorithm and texture mapping.
Experimental results are shown in Section 6, and
conclusions are given in Section 7.

2. Constructing the dataset of generic
models

There is the same basic structure such as eyes, nose
and mouth etc for different people. It‚Äôs easy for us to
identify a generic model with them. Everyone has
different features that make one unlike others. A
generic model should be a structural one for facial
animation. The wireframe model is gettable from much
software such as 3DMAX, Poser or Maya. It‚Äôs usually
chosen as a facial model.
From Poser 5.0, we randomly derive 50 male and
50 female head models that are respectively made of
8172 3D vertexes and 15980 triangles. They represent
different face shape such as the shape of a circle, a
rectangle or a triangle.

(a)

(b)

Figure 2. A generic model : (a) Feature points
identifying (b) Feature points

3. Geometrical Measurement
Different face shape can be represented with global
proportional relationships of the face. According to
facial physiological structure and geometrical relation
between feature points, we identify 6 horizontal
measurements and 8 vertical measurements. Both
horizontal and vertical measurements are shown in
Figure 3. We choose 6 horizontal proportions and 6
vertical proportions to represent the facial geometrical
shape. Table 1 shows several examples of the means
and standard deviations (SD) of human facial
proportions. The results are based on facial
measurements of 100 Asian (50 men and 50 women)
who have been described in Section 2.

H1

Figure 1. Dataset of generic models: The first
and second lines are parts of male models. The
third and fourth lines are parts of female models.
According to MPEG-4, there are 84 feature points
defined on a neutral face that provides referenced
space for defining facial animation parameter (FAP).
They suffice for identifying proper shape of facial
model. Feature points are divided into several groups
such as lip, eyes and mouth etc. There are 79 feature
points selected according to MPEG-4 and facial shape
in this paper. Figure 2 shows their position. We may
obtain feature points of every model in the dataset.

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV‚Äô05)
0-7695-2392-7/05 $20.00 ¬© 2005 IEEE

H2
H3
H4
H5
H6

(a)
(b)
Figure 3. Measurements on human face:
(a) Front view (b) Side view
Table 1. Some proportions on human face
(a) Facial horizontal proportions (%)
H2 H3
H4
H5
H6
Proportion
H1 H1
H1
H6
H1
Mean 23.4 61.0 27.5 55.2 66.1
M
2.1
2.9
2.1
6.8
3.4
SD
22.7
62.8
22.5
53.4
66.2
Mean
F
2.0
2.8
1.9
6.5
3.3
SD

H2
H3
38.4
2.9
36.2
2.7

(b) Facial vertical proportions (%)
V3
V2
V4
V7
V8
V6
Proportion
V1
V3
V3
V3
V3
V5
Mean 81.7 22.5 58.8 41.2 62.1 41.6
M
1.7
2.6
4.5
4.4
2.9
11.7
SD
78.5
27.5
61.3
38.7
59.9
43.4
Mean
F
1.8
3.0
4.9
4.9
3.2
10.0
SD
Every measurement is listed as follows:
H1=86.x-68.x
(1)
where 86.x is the x coordinate of Point 86, 68.x is
the x coordinate of Point 68. Feature points are shown
in Figure 2. It‚Äôs likewise from formula (2) to formula
(6).
H2=8.x-0.x
(2)
H3=12.x-4.x
(3)
H4=44.x-39.x
(4)
H5=54.x-48.x
(5)
H6=81.x-73.x
(6)
V1=18.y-77.y
(7)
where 18.y is the y coordinate of Point 18, 77.y is
the y coordinate of Point 77. It‚Äôs likewise from formula
(8) to formula (14).
V2=18.y-4.y
(8)
V3=4.y-77.y
(9)
V4=4.y-48.y
(10)
V5=51.y-57.y
(11)
V6=51.y-54.y
(12)
V7=54.y-77.y
(13)
V8=42.y-77.y
(14)

4. 3D head models retrieval
4.1 Extraction of frontal facial feature points
We propose an improved Active Shape Model
(ASM) method, RealBoost Gabor ASM(RG-ASM), in
which local appearance models of key points are
modeled using statistical learning. RealBoost is
proposed to build the likelihood model that ensures the
ground truth position of each key point will more
likely have a higher likelihood than its neighbors.
Instead of using principle components analysis and one
pixel Gabor coefficients, Gabor wavelet features of
key point and its neighbors are used as the feature
space in the learning procedure to model local
structures of a face. More details could refer Huang‚Äôs
paper [9].

Figure 4. Results of detecting facial feature
points

4.2 Generic model retrieval
After we extract the facial feature points of the
performer, both measurements and proportions can be
obtained according to what we have described in
Section 3. Then we compare the proportions of the
performer and the sample. Because there are a male
dataset and a female dataset, we manually choose one
or other. The formula is:
5

5

i 0

j 0

Ep = ¬¶ P( HP(i)) * ( HP(i)  H p (i)) 2  ¬¶ P(VP( j )) * (VP( j )  V p ( j )) 2
(15)
where

HP(i)

and

H p (i )

are respectively the ith

horizontal proportion of the performer face and the pth
sample face, P( HP(i)) is the weight of ith horizontal
proportion, it‚Äôs determined according to formula (16),
VP( j ) and V p ( j ) are respectively the jth vertical
proportion of the performer face and the pth sample
face, P(VP( j))) is the weight of jth vertical proportion,
it‚Äôs also determined according to formula (16).
We assume the proportion is normal distribution,
and the probability function may be considered as the
weight of the proportion.
P( x i)

1
2S V i

e

1 ¬ß xi  P i ¬∑
¬∏
 ¬®
2¬® V i ¬∏
¬©
¬π

2

(16)

where x i is the horizontal proportion or vertical
proportion of the performer face, P i and V i are
respectively the mean and the standard deviation of the
relevant proportion (Their values are listed in Table 1).
After obtaining Ep of every sample, the generic
model with the minimum Ep is what we want. Figure 4
shows retrieval results corresponding to Figure 3.

Figure 5. Retrieval results of generic models

5. Deformation and texture mapping
Given the feature points derived from face detection,
deforming the retrieval generic model with

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV‚Äô05)
0-7695-2392-7/05 $20.00 ¬© 2005 IEEE

corresponding feature points is straightforward. After
that, texture mapping results in the final individual face.
The facial model adjustment is a problem about 3D
space deformation in fact. We identify limited control
points on it and compute their displacements, then
choose an interpolation function which accommodates
displacements of control points. Locations of the rest
nodes are transformed upon the function.
There are several choices for how to construct the
interpolating function. We use a method based on
radial basis functions (RBF) as approximation
functions for their power to deal with irregular sets of
data in multi-dimensional space in approximating high
dimensional smooth surface. More details could refer
Zhang‚Äôs paper [10].
Texture mapping makes the synthetic face more
photorealistic. We may generate a blended texture map.
After texture fitting, we may get a realistic facial
model. Zhang [10] gives the detail steps of texture
mapping.

6. Experiment results
The implementation of the above described
individual face generation system is written in VC++
and OpenGL. Some detailed individualized heads are
shown in Figure 5 where input images are shown in
Figure 3. They have proper shape and texture.

Figure 6. Snapshots of reconstructed heads

in several views

7. Conclusion
In this paper, we introduce a 3D head models
retrieval algorithm based on geometrical measurement

Proceedings of the Computer Graphics, Imaging and Vision: New Trends (CGIV‚Äô05)
0-7695-2392-7/05 $20.00 ¬© 2005 IEEE

for modeling. It reduces deformation error of the
generic model. The experiment results show that it is
simple and efficient.
The aim of this paper is to improve the quality of
the results. Possible ways to improve it include the
depth estimation of feature points, improving the
merging image and adding hair modeling.

8. Acknowledgment
We are grateful to people taken photos. This project
is supported by Chinese National Research Foundation.

9. References
[1] W. Lee, and N. Magnenat-Thalmann, ‚ÄúFast Head
Modeling for Animation‚Äù, Journal Image and Vision
Computing, Volume 18, Number 4, Elsevier, March, 2000,
pp.355-364.
[2] V. Blanz, and T. Vetter, ‚ÄúA Morphable Model for the
Synthesis of 3D Faces‚Äù, In Proceedings of ACM SIGGRAPH
99, AddisonWesley, New York, A. Rockwood, Ed., Annual
Conference Series, pp.187-194.
[3] F. Pighin, J. Hecker, D. Lischinski, R. Szeliski, and D. H.
Salesin, ‚ÄúSynthesizing Realistic Facial Expressions from
Photographs‚Äù, Siggraph proceedings, 1998, pp. 75-84.
[4] Z.C. Liu, Z.Y. Zhang, C. Jacobs, and M. Cohen. ‚ÄúRapid
Modeling of Animated Faces from Video‚Äù, Technical Report,
MSR-TR_2000-11.
[5] M.Q. Zhou, X.N. liu and G.H. Geng, ‚Äú3D Face
Recognition Based on Geometrical Measurement‚Äù, Proc. of
5th Chinese Conference on Biometric Recognition,
SINOBIOMETRICS 2004, Guangzhou, China, 13-14 Dec.
2004, pp.244-249.
[6] Y. Lee, ‚Äú 3D Face Recognition using Longitudinal
Section and Transection‚Äù, Proc. VIIth Digital Image
Computing: Techniques and Applications, Sun C., Talbot H.,
Ourselin S. and Adriaansen T. (Eds.), Sydney, 10-12 Dec.
2003, pp.49-58.
[7] V. Starovoitov and D. Samal, ‚ÄúA geometric approach to
face recognition‚Äù, Proc. of Workshop Nonlinear Signal and
Image Processing, vol. I, Antalya, Turkey, June 1999, pp.
210-213.
[8] H.S. Horace and W. Wong, ‚Äú3D Head Model Retrieval
Based on Hierarchical Facial Region Similarity‚Äù, Proc. of
15th International Conference on Visual Interface (VI2002),
Calgary, Canada, 27-29 May 2002, pp. 314-319.

[9] X.S. Huang, X. Bin, Y.S.Wang Yangsheng. "Shape
Localization by Statistical Learning in the Gabor
Feature Space" ICSP04, Beijing, China, Sep. 2004,
pp.1385-1389.
[10] M.D. Zhang, P. Lu, X.S. Huang, X.X. Zhou, Y.S. Wang
"Video-Based Fast 3D Individual Facial Modeling", the 14th
International Conference on
Artificial Reality and
Telexistence (ICAT04), Coex, Korea, Nov.30-Dec.2, 2004,
pp.269-272.

