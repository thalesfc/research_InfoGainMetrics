12th International Conference Information Visualisation

Multitarget Tracking Using Mean-shift with Particle Filter based Initialization

Satoshi Yonemoto, Motonori Sato
Kyushu Sangyo University, 2-3-1 Matsukadai, Fukuoka-city Fukuoka, 813-8503 Japan
yonemoto@is.kyusan-u.ac.jp

Abstract

2. Mean-shift tracking

This paper presents a multitarget tracking
algorithm based on mean-shift, in which an automatic
initialization process by particle filter is utilized. In the
standard mean-shift algorithm, this initialization is
necessary to construct the reference target model to
track. In our approach, switching between the particle
filter based detection and the mean-shift tracking is
introduced. Furthermore, we extend mean-shit
tracking with particle filter based initialization into
multitarget tracking problem. We experimentally show
that our method can track multiple targets in outdoor
situation and can run in real-time on a PC.

In our approach, color features are employed to
characterize a target. We use a mean-shift (MS) tracker
by comparing the histogram of its candidate with the
histogram of the target model using the Bhattacharyya
coefficients between their histograms.

2.1. Target representation
The reference target model is represented by the mbin histogram
qÀÜ ^qÀÜu ` u 1 ~ m  . In the
subsequent frame, a target candidate at a given location
y is also characterized by the color histogram
u 1~m . Their histograms are
pÀÜ  y  ^pÀÜ u  y `

1. Introduction

computed from the pixels in the target search region.
Thus we have

Target tracking is important for visual surveillance
and monitoring and is useful for a wide range of
visualization tools [6]. In this context, we focus on
multitarget tracking using color based image features.
The mean-shift tracking is one of robust tracking
algorithms to track a non-rigid target by using color
distributions and is used by many computer vision
researchers [1][2]. Color distributions provide an
efficient feature for target tracking problems since they
are robust to partial occlusion and appearance changes.
In this algorithm, the target model is represented by
color distribution (discretely color histogram) which is
acquired from the target search region. We use the
mean-shift tracker to track targets such as walking
persons or cycling persons in outdoor situation.
One of the limitations of this approach is that it is
necessary to construct the initial reference model to
track in advance. It is difficult to consider possible
variations of color distributions since they depend on
target appearances such as colors of clothes or
paintings. Therefore, an automatic initialization
process is required for online mean-shift tracking. For
this reason, we introduce an automatic target model
acquisition by particle filter into mean-shift tracking.

1550-6037/08 $25.00 ¬© 2008 IEEE
DOI 10.1109/IV.2008.43

m

^qÀÜu ` u 1 ~ m  with ¬¶ qÀÜ 1
target candidate: pÀÜ  y  ^pÀÜ u  y `
u 1 ~ m with

target model: qÀÜ

u

u 1

m

¬¶pÀÜ (y)
u

1

.

u 1

2.2. The mean-shift algorithm
*

First, target model acquisition is required. xi is the
normalized pixel location in the target model region,
which has n pixels. Each value qÀÜu is computed as

>  @

n

qÀÜ u

2
C ¬¶ k ¬ß¬® xi* ¬∑¬∏G b xi*  u ,
¬©
¬π
i 1

(1)

where G [x ] is the Kronecker delta function. C is the
normalization constant. We use the Epanechnikov
kernel as a kernel profile k  x . Using the kernel
profile k x  , the target candidate is given by
n
¬ß y  xi 2 ¬∑
,
(2)
¬∏G [bx i   u ]
pÀÜ u y  Ch ¬¶ k ¬®
¬®
¬∏
i 1

¬©

h

¬π

where C h is the normalization constant and h is the
scale factor.

521

About the implementation, our work has evolved
from the Condensation algorithm which was proposed
by Isard et al. [3][4][5].
The parameter of a tracked object at time t is
represented by the vector xt . Similarly, an image

The similarity measure between pÀÜ and qÀÜ is defined as
(3)
d  y  1  U > pÀÜ  y , qÀÜ @ ,
where the Bhattacharyya coefficient between pÀÜ and
qÀÜ is given by
UÀÜ  y  U > pÀÜ  y , qÀÜ @

m

¬¶

pÀÜ u  y qÀÜ u .

(4)

observation is represented by the vector yt . The
vector Y t ^y1 , y2 ,, yt ` denotes all observations up to

u 1

Using Taylor expansion around the value pÀÜ u  y0  , the
linear approximation of the Bhattacharyya coefficient
is obtained as
¬ß y  xi 2 ¬∑ , (5)
1 m
Ch n
¬∏
¬®
U > pÀÜ  y , qÀÜ @ |
m

¬¶ pÀÜ  yÀÜ qÀÜ
0

u



u 1

2

¬¶ w k¬®
i

i 1

¬©

h

observation data yt from an image.
By applying Bayes' rule, inferring the posterior
distribution p( xt | Yt ) is interpreted as

¬∏
¬π

qÀÜ u
G >b xi   u @ .
ÀÜpu  yÀÜ 0 

¬¶

where wi

2

time t . The tracking problem is to find a target object
parameterized as xt with prior p( xt ) , using

u 1

Thus, the tracking task is to minimize the distance
(3), employing the mean shift iterations. For the
iterations, the new location yÀÜ1 of the target candidate
is updated from the current location yÀÜ 0 as
¬ß yÀÜ 0  xi 2 ¬∑
¬®
¬∏
w
x
g
¬¶
i i
¬®
¬∏ ,
h
i 1
¬©
¬π
n
¬ß yÀÜ 0  xi 2 ¬∑
¬∏
wi g ¬®
¬¶
¬®
¬∏
h
i 1
¬©
¬π

p y t xt  pxt Yt 1  ,
p y t Yt 1 

pxt Yt 1 

¬≥ px

(7)

where
t

xt 1  pxt 1 Yt 1 dxt 1

.

(8)

Furthermore, in the PF framework, the tracking
problem is to approximate the posterior distribution
p ( xt | Yt ) using a discrete set of samples (particles).

n

yÀÜ1

pxt Yt 

(6)

Each sample corresponds to a hypothesis on certain
target state.
The standard PF performs the following steps:
selection, prediction, measuring and updating.

where g  x  k '  x  .
In summary, the mean-shift algorithm for a known
target proceeds as follows:
1. Generate a histogram of the target candidate.
2. Evaluate the similarity between using (3).
3. Repeat steps 1-2 until convergence.

Step 1 Selection: The posterior distribution at time
t  1 is represented by a set of N particles denoted by
^s t(n1) `. The new set of N particles ^stc (n) ` is re-sampled

from ^s t(n1) `.

The main problem of color feature based tracking is
how the target model should be acquired. In particular,
for online system, an initial model of a target to track
must be automatically constructed.

Step 2 Prediction: The sample set is propagated by
prediction. In the simplest case, each sample
s tc ( n ) ~ p ( x t | x t 1 s tc ( n ) ) is updated according to a
stochastic diffusion model
xt xt-1  vt ,
where vt is a vector of random variables.

3. Particle filter based initialization
We use a particle filter to automatically construct a
target model for mean-shift tracking.

(9)

Step 3 Measuring and updating: Given an observed
N

3.1. Particle filter

S t( n) 1 ) is
image feature yt , each weight S t(n ) (where ¬¶
n 1
updated by using the likelihood function
p ( yt | xt st( n ) ) .

Particle filter (PF) has proven successful for nonlinear and non-Gaussian estimation problems. PF is
based on the Bayesian framework. In particular, in
computer vision, it has been often applied to tracking
targets in clutter since the idea of PF provides a robust
tracking framework.

(n )
(n )
Using the sample set ^st ` with the weights ^S t ` ,
the parameter xÀÜt can be estimated by
N
(10)
xÀÜ
S ( n) s ( n) .

t

¬¶
n 1

522

t

t

For complicated situation, a wider monitoring area is
required.

3.2. Target representation
We have to detect human blob as an image
observation to start the mean-shift tracking. We
currently use the foreground pixels which are extracted
by background subtraction. In the above PF approach,
each sample of the distribution corresponds to a kernel
model (ellipse) since the estimation results can be
directly utilized for the mean-shift tracker. It is given
as
st( n )

^x , y , l1 , l2 ` ,

(11)

where x , y specify the center of the kernel and l1 , l2
the length of the half axes.
The likelihood function

p ( yt | xt

st( n ) ) is defined

Figure 2 Monitoring areas.

by the density of the foreground pixels in the kernel
region.
Figure 1 shows an example of the PF tracking
results. Figure 1(a) shows the input image clip, and (b)
shows the foreground pixels in the image, which are
overlaid the estimated kernel (blue ellipse) and the set
of the particles (blue dots). Figure 1(c) shows the real
states of the particles (dark green ellipses). The kernel
successfully represents an approximation of a human
blob, so the largest connected region, in other words,
the upper body region is locked on [7].

4. Multitarget tracking
We extend mean-shift tracking with PF based
initialization into multitarget tracking problem.
Our multitarget tracking algorithm for the above
situation proceeds as follows:
1. Allocate lPF1 and rPF1 in each monitoring
area. ^lPFi ` (i 1,..., I ) denotes the left side

2.

PFs. Similarly, ^rPFj ` ( j 1,..., J ) denotes the
right side PFs.
If lPFi or rPF j captures an appeared target,
then change the PF detector into a new MS
tracker MSk . ^MS k ` (k 1,..., K ) represents a

(a)

(b)

set of the generated trackers. Switching
between the PF and the MS is done by
evaluating the goodness of the likelihood
function associated with the density of the
foreground pixels. We currently use simple
threshold criteria for the evaluation. After
MS k accepts the estimation results of the PF,

(c)

Figure 1 An example of the PF tracking results.
(a) the input image. (b) the foreground pixels and
the estimated kernel. (c) the set of the particles.

then the PF is destroyed. For several intervals,
re-allocate a new lPFi ' (i ' i  1) or
rPF j '

( j'

j  1)

in

the

corresponding

3.3. Monitoring areas

3.

monitoring area.
If MSk gets out of the visible area, then it is

Figure 2 shows typical outdoor situation where
pedestrians can walk the road only in left or right
direction toward the camera. In this case, we set two
monitoring areas L, R on both sides. Each PF the
above mentioned is allocated in the corresponding area
to monitor entrance and exit. The definition of the
monitoring areas depends on the camera allocation.

4.

destroyed.
repeat 2-3.

523

side. Figure 3(a) shows the results of the proposed
method. The tracks are noisy while the PF does not
capture any target. After capturing a target, the tracker
successfully tracks it. Figure 3(b) shows the result of
the standard PF. The tracking failed for the influence
of temporal occlusion.
We have also tested the proposed method for the
other image sequences. Figure 6 shows the successful
sequences. Figure 6(a) shows a scene where two
persons and a cycling person enter. Though a cycling
person exists, tracking of three persons is successfully
performed. Figure 6(b) shows the successful tracking
result under illumination changes. However, for the
sequence shown in Figure 5, the proposed method
could not track two persons separately since the
persons enter simultaneously. Only one person could
track successfully.

5. Experiments
We compare the performance of the proposed
method with the standard PF tracking algorithm by
using surveillance sequences.

5.1. Setup
The proposed algorithm was tested with a few
surveillance sequences of 300 frames to demonstrate
the efficiency. The image size is 640 x 480 pixels. The
sequences were captured at 15 fps using the IEEE
1394 digital camera. A Core2duo-2.4GHz PC under
linux is employed.
In this experiment, we assumed typical outdoor
situation where pedestrians can walk only in left or
right direction toward the camera. As mentioned
before, the definition of monitoring areas depends on
the camera allocation, so, in this case, two monitoring
areas are arranged within the image region.
The background statistical model is first learned,
which is used by background subtraction process. In
this experiment, 300 frames are used to construct the
statistical model. As a person enters the field of the
camera, the foreground pixels are extracted by the
statistical background subtraction. A PF is allocated in
the corresponding monitoring area and attempts to
track each of human blobs independently. Once a
person is within the field of the camera, the close PF
captures his or her upper body region. The PF
estimates the optimal location which includes the
foreground pixels as much as possible.

·ç∑

·çπ·ç∑·ç∑

·çª·ç∑·ç∑

·çΩ·ç∑·ç∑

·ç∑
·çº·ç∑
·ç∏·ç∑·ç∑
·ç∏·çº·ç∑
·çπ·ç∑·ç∑
·çπ·çº·ç∑
·ç∫·ç∑·ç∑
·ç∫·çº·ç∑
·çª·ç∑·ç∑
·çª·çº·ç∑

·é≥·éó·éç·ç∏·ç≤·éî·éö·çπ
·éπ·éó·éç·ç∏·ç≤·éî·éö·ç∏
·éπ·éó·éç·çπ·ç≤·éî·éö·ç∫

(a) PF+MS (the proposed method)
·ç∑

·çπ·ç∑·ç∑

·çª·ç∑·ç∑

·çΩ·ç∑·ç∑

·ç∑
·çº·ç∑
·ç∏·ç∑·ç∑
·ç∏·çº·ç∑
·çπ·ç∑·ç∑
·çπ·çº·ç∑
·ç∫·ç∑·ç∑
·ç∫·çº·ç∑
·çª·ç∑·ç∑
·çª·çº·ç∑

5.2. Multitarget tracking results
We have tested the proposed method for multitarget
tracking. The results with multitarget tracking are
summarized in Figure 4 (left is input image and right is
the estimation result). During the sequence three
persons enter and exit. In Figure 4(a), lPF1 and rPF1
are allocated (blue ellipses). In each PF, N 100
particles are used. In Figure 4(b), switching between
rPF1 and MS 1 (green ellipse) is done after rPF1
captures a first appeared person. Similarly, In Figure
4(c), switching between lPF1 and MS 2 (black ellipse)
is done and rPF2 is allocated. In Figure 4(d),
switching between rPF2 and MS 3 (green ellipse) is

·éó·éç·çπ
·éó·éç·ç∏

(b) PF only
Figure 3 Track of multitargets.

done. In Figure 4(d)(e), the trackers ^MSk ` (k 1,...,3)
can successfully recover from temporal occlusion.
Figure 3 shows the tracks for three persons. Green
and red lines indicate the person appeared from right
side. Black line indicates the person appeared from left

524

(a) frame 000: initial scene (no target).

Figure 5 Failure sequence.

(b) frame 045: switching bet. rPF1 and MS1 .

(a) A cycling person has entered.

(c) frame 071: switching bet. lPF1 and MS 2 .

(b) Illumination change yields large variations.
Figure 6 Successful image sequences.
(d) frame 096: switching bet. rPF2 and

MS3

.

5.3. Implementation for real-time applications
We have applied the proposed method to a real-time
tracking system by using the above PC in which a
single IEEE1394 digital camera is installed. The
computing time of our method depends on the number
of targets which are simultaneously tracked.
Concretely, it takes about 20 msec. to track in a MS,
and it takes about 28 msec. in a PF. In short, in the
proposed method (PF+MS), it takes maximum 28 msec.
per one person. Consequently, in PF+MS, it takes
about 28 u 2  20 u M  msec. when M persons exist (for
example, it takes about 116 msec. when three persons
exist). The system could track targets for changing
illumination conditions.

(e) frame 134: after temporal occlusion.
Figure 4 Multitarget tracking results

525

Conference Computer Vision and Pattern Recognition,
pp.142--149, 2000.

6. Conclusions
We described multitarget tracking algorithm based
on mean-shift tracker with initialization. In the
algorithm, the automatic initialization to construct the
reference target model for the mean-shift tracker is
realized by using particle filter, which performs elliptic
region tracking. Switching between the particle filter
detection and the mean-shift tracker is properly
introduced. Furthermore, we extend the mean-shit
tracking with the particle filter based initialization into
multitarget tracking problem. We experimentally show
that our method can track multiple targets in typical
outdoor situation and can run in real-time on a PC.
For future work, we consider the use of more
complicated methods for PF based initialization. In
principle, PF has the flexibility as a multiple target
tracker in which the number of targets and their
locations could be simultaneously estimated [8]. We
have to apply the proposed method as a visualization
tool for the practical situations such as railway stations,
parking areas and shopping malls.

[3]

M. Isard and A. Blake, Condensation ‚Äì conditional
density propagation for visual tracking, In
International Journal of Computer Vision, 29(1),
pp.5‚Äî28, 1998.

[4]

M. Isard and A. Blake, Contour Tracking by
Stochastic Propagation of Conditional Density, In Proc.
European Conference of Computer Vision, pp.343‚Äî
356, 1996.

[5]

M. Isard and A. Blake, Icondensation: Unifying lowlevel and high-level tracking in a stochastic framework,
In European Conference of Computer Vision,
pp.893‚Äî908, 1998.

[6]

I. Haritaoglu, D. Wharwood, and L. Davis, W4S: A
real-time system for detecting and tracking people in
2.5D, In Proc. European Computer Vision, pp. 877-892, 1998.

[7]

C. Wren and A. Pentland, Pfinder: Real-time tracking
of the human body, IEEE Trans. on Pattern Analysis
and Machine Intelligence, 19, pp.780-785, 1997.

[8]

M.Isard, J.MacCormick, BraMBle: A Bayesian
Multiple-blob Tracker, In Proc. of International
Conference on Computer Vision, pp.34--41, 2001.

References
[1]

[2]

D Comaniciu, V Ramesh, P Meer, Kernel-based object
tracking, IEEE Trans. on Pattern Analysis and
Machine Intelligence, 25, No. 5, pp. 564-577, 2003.
D. Comaniciu, V. Ramesh, and P.Meer, Real-time
tracking of nonrigid objects using mean shift, in Proc.

526

