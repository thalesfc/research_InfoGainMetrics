Face Representation and Reconstruction under Different Illumination Conditions
Haitao Wang 1, Yangsheng Wang 1, Hong Wei2,
1

Institute of Automation, Chinese Academy of Sciences,
2
Dept. of Computer Science, University of Reading,
E-mail: 1htwang@nlpr.ia.ac.cn; 2h.wei@reading.ac.uk

Abstract
To deal with image variations due to illumination
problem, Ramamoorthi and Basri have independently
derived a spherical harmonic analysis for the Lambertian
reflectance and linear subspace. Their theoretical work
provided a new approach for face representation,
however both of them assume that the 3D surface
normals and albedo (or unit albedo)are known, which
limit this algorithm‚Äôs application. In this paper, we
present a novel method for modeling 3D face shape and
albedo from only three images and this work well fill the
blank, which Ramamoorthi and Basri left. Our work is
closely related to photometric stereo, but conditions of
photometric stereo for estimating albedo and surface
normal are too strict to be applied for real application.
Moreover, the conventionally used singular value
decomposition (SVD) approach will lead to the notorious
linear ambiguity and the solvent of this problem will need
to introduce more constrains or more images. By taking
the advantage of similar 3D shape of all human faces, the
highlight of the new method is that it circumambulates the
linear ambiguity by 3D alignment. The experiment results
show that our estimated model can be perfectly employed
to face recognition and 3D reconstruction.

1. Introduction
Illumination problem is one of the most challenging
tasks in computer vision. In real applications, differences
due to the illumination changes may significantly exceed
the differences due to different identities. Furthermore
slight changes in lighting conditions will cause great
variations in face image gray value distribution. This is
the reason why illumination is listed in the table of the
main difficulties for face recognition [1].
To cope with this problem, traditional principle
component analysis (PCA)-based [3] approach needs
large number of images sampled under different
illumination conditions. This is computationally
intractable. Therefore the models built by PCA are always
biased for the scarcity of sample images. In addition, this
approach can be applied only to point light source, which

is contrary to real world, where the light sources are
usually area lights and have large continuous lighting
distributions.
To represent face under all possible lighting
conditions, many research [4][5][6][10] have done large
number of experiments. Their empirical study showed
that human face, as a typical example of Lambertian
object, does lie in a low-dimensional subspace and the
first five or seven principle components can explain the
image variations due to lighting changes very well.
However there is no theoretical foundation to support
their explanations.
Recently, two researchers, Ramamoorthi [7][8] and
Basri [9] have independently worked out the mechanism
of image variations under different illumination condition
by spherical harmonic theory. By their spherical harmonic
analysis results, we do not need sample all the images
produced by varied lighting conditions, such as in the
case of illumination cone [12] and the light source can be
any type, e.g. point, area, or any combination of them.
Though their work has provided a new method for
face representation, both of them assume the known 3D
surface normal and albedo (or unit albedo). This
assumption limits the application of this algorithm. In this
paper, we present a novel method for modeling face‚Äôs 3D
shape and albedo from only three images and apply the
results for the 3D reconstruction and recognition. The
arrangement of this paper is as follows. In section 2, we
briefly describe the spherical harmonic representation of
face images and elaborate our modeling process. In
section 3, the surface normal estimated in the previous
section is utilized for 3D reconstruction and the nine
harmonic images are employed for recognition in section
4. In section 5, we discuss the experiment results and the
conclusion is made in the final section.

2. Face Representation by
Harmonics and Modeling Process

Spherical

Experiments by Hallinan [10], and Epstein [4] have
demonstrated that human face images under different
lighting conditions lie in a low-dimension subspace,
which can be approximated by PCA. But their works
were based on empirical data. Recently Ramamoorthi
[7][8] and Basri [9] independently and theoretically

Proceedings of the Seventh International Conference on Information Visualization (IV‚Äô03)
1093-9547/03 $17.00 ¬© 2003 IEEE

analyzed the relationship between the low-dimensional
subspace and the spherical harmonic images, which
indicates that the complex illumination problem in
computer vision, can be explained in theory.

2.1. Spherical Harmonic Representation
In this subsection, we briefly introduce the work of
[7][8][9]. Let‚Äôs assume that human face F is a Lambertian
object and is illuminated by distant isotropic light
sources. Let (x, y, z ) and ( , ) be the surface normal and
the spherical coordination of point P on the surface of F
respectively. The relationship between them is
( x, y, z ) (cosT sin I , sin T cos I , cos I ) (1)
where 0 d T d S ,

2

h20

0.3154(3n z  1) ;

h22

0.5462(n x  n y )

2

2

(6)

where (nx, ny, nz) is the surface normal of face.
Therefore the harmonic image is constructed as
follows:
bnm ( p ) Urnm (n x , n y , n z )
(7)
where is the face albedo.

0 d I d 2S .

The reflectance of point p by a point light source l( ,
) is defined by

r (T , I )

2S

S

0

0

¬≥ ¬≥

k (T ) L(T , I ) sinTdTdI

(2)

where k (T ) max(cosT ,0) .
And we can refer equation (2) as a convolution
r (T , I ) k * l
(3)
The spherical harmonics are a set of functions that
form an orthonormal basis on the sphere, which is
analogue to Fourier basis convoluting in the plane. These
functions are denote by hnm, with n = 0, 1, 2,..., and -n@
m@n:
hnm (T , I ) N n,m Pn,m (cosT )exp(ImI )
(4)

(a) the first nine harmonic images of a sphere

where Nn,m is a normalization factor, Pnm is the Legendre
functions, Im is the imaginary sign.

K (T , I )

¬¶K

nm

hnm (T , I )

n ,m

l (T , I )

¬¶l

nm

hnm (T , I )

n ,m

r (T , I )

¬¶C

nm

hnm

(5)

n ,m

Analytical study of Ramamoorthi [7][8] and Basri [9]
shows that Knm vanishes for odd values of n>1 and the
even terms fall to zero rapidly. Moreover the second
order approximation (first nine terms) captures more than
99% of the energy. For more detail of Knm, hnm and rnm,
one can reference [7][8][9].
Consequently the reflectance function denoted by
harmonic light hnm is
The first nine harmonics are

h00 0.2821 ;
h11 ,h10 , h11 0.4866(n x , n y , n z ) ;

(b) the first nine harmonic images for a face
Figure 1. The first nine harmonic images of a sphere and
a face
Figure 1 shows the harmonic images of a sphere and a
face. These harmonic images bnm form an analytical
subspace of face under different lighting conditions under
the assumption that the surface normal and albedo are
known. However Ramamoorthi [7][8] and Basri [9] did
not provide a practical approach for estimation of these
parameters. Therefore a practical algorithm of modeling
the face parameters is imperative to make the spherical
harmonic representation more applicable.

2.2. Our New Method of Modeling

Proceedings of the Seventh International Conference on Information Visualization (IV‚Äô03)
1093-9547/03 $17.00 ¬© 2003 IEEE

By the Lambertian Model [3], a face image can be
described as equation (8)

U ( x, y ) n T ( x, y ) s ,

I ( x, y )

(8)

where I is the p u 1 face image with all the p pixels
concatenated by row or by column, U (>0) is the

p u 1 albedo(surface texture), nT is the p u 3 surface
normal of face and s is the 3 u 1 light source vector with
unit intensity. For face image with attached shadow
T

( n s  0 ), equation (1) can be written as equation (9).

I ( x, y )

max(0, U i ( x, y )n( x, y )T s j )

(9)

We assume that we have three images for each face
with equal intensity, non-collinear light source direction
and small shadow. Under this assumption, we can model
the face albedo and surface normal with linear ambiguity.
Let I1, I2, I3 are the three images for a face, nT is the
surface normal for this face and s1, s2, s3 are the
corresponding light source direction of the three images.
Using the (SVD) singular value decomposition [6][11],
we have

J

[ I1 , I 2 , I 3 ]
UDV

UnT [ s1 , s2 s3 ] SVD( J )

Un*T S *

(10)

transform the UDV form into

*T

Un S

B and n*T

*

form, where

¬™b1 / B ¬∫
¬ª
¬´
¬ª.
¬´...
¬´b / B ¬ª
¬º
¬¨ p

Because V is orthogonal and has unit length and the
three light sources are not collinear, the column V can be
seen as the three rotated light sources with unit length, the
rank of which must be 3.
There is an invertible matrix A, which satisfies

and

*

*T

Let assume the n and S* of each face have the same
ambiguity matrix A, then the estimated light direction in
one face model can create identical illumination effect
images for the other faces in the database.
Therefore a simple way to circumambulate this
problem is to align all face models by Ci so that the
ambiguity matrix is the same for all face models. The
assumption of this method is that all faces have a similar
3D shape. Let E be the alignment energy function,

(n0T  ni*T C i )(n0T  ni*T C i ) T

E

i 1,..., m
(13)
T

where m is the number of face model, n0 is the alignment
*T

where D is a diagonal matrix whose elements are the
square roots of the eigenvalues of JJT. U is the p u 3
matrix, the columns of which are corresponding to the
normalized eigenvectors of the matrix JTJ. And V is
3u 3 matrix, whose columns are the eigenvectors of JJT.
Since the matrix J is composed of three image, we can

S * V , B UD , U

*T

not affect the images formed by n and S . This result
is obvious because the ambiguity matrix A rotates nT and
S at the same time, therefore their dot product does not
change. In fact, this ambiguity can be discard in the face
model, such as in the formation of illumination cone in
[9]. However, if this ambiguity is not solved, we must
estimate the light direction of input image one time for
each face model, which will lead to high computation
expense in recognition.

nT n*T A
S A 1 S *

(11)
(12)

where nT and S are the true surface normal and light
direction of face image I.
This linear ambiguity is belonging to a subset of GBR
[14]. According to Belhumeur [14], this ambiguity does

model and ni the face model. Minimizing this function
by least squares technique, we get

dE
dC i

0

2ni* n0T  ni* ni*T C i

(ni* ni*T ) 1 ni* n0T .

Ci

(14)

Then all the surface normals are aligned according to
T
0

n by
n~iT

ni*T C i

(15)

T

If n0 is the true surface normals of a face, the
ambiguity matrix will disappear. Our algorithm is similar
to that of Epstein and etc [15], but they do not exclude the
albedo effects. Moreover a prototype [15] is needed to
estimate the rotation matrix Ci. In our method, every face
model n

*T

T

can be the prototype n0 and the albedo is

excluded from the estimation. Therefore we can align all
the surface normals to any n*Tcalculated in equation (10)
and any surface normal from SVD can be seen as the
prototype. In fact from the equations (11) and (12), it can
be deduced that the rotation of surface normal is also
implied the same rotation of illumination direction and

Proceedings of the Seventh International Conference on Information Visualization (IV‚Äô03)
1093-9547/03 $17.00 ¬© 2003 IEEE

the viewpoint direction. So by 3D alignment we do not
need to estimate the light source direction of one input
image for every face model in recognition process. Hence
if the light source is estimated in one face model, it can
also be applied to another for synthesizing similar
illumination effects without involving in any ambiguity.
Figure 2 shows that a face model can be used as
prototype to align the other model.

expensive. We purpose an iterative algorithm for this
problem, which much fast than that of Basri [](only
several seconds for a 100 √ó 100 image by Matlab in
Pentium ‚Ä¢ 866 machine).
Our new algorithm is a iterative function, which has a
simple form as

zk (x, y)

1 k1
(z (x 1, y) p(x 1, y)  zk1(x, y 1)q(x, y 1)
4
 zk1(x 1, y) p(x, y)  zk1(x, y 1)q(x, y))

(18)
where (x,y) range over all the image and k = 1, 2,‚Ä¶,n.
(a) Face images

0

(b) Its corresponding surface normal in nx, ny, nz

For k =0, which means the initial state, z ( x, y ) 0 .
The main idea of this function is that we use the four
neighbors (the gray squares in Figure 3) of z(x,y) to
estimate its height with an unknown scale.

(c) Another face images

(d) Its corresponding surface normal from SVD

Figure 3. estimation of z(x,y)
(e) After the 3D alignment
Figure 2. 3D alignment

3. Face
Normals

Reconstruction

from

4. Face Recognition
Surface

From the previous section, we know that if the surface
normals are aligned by a prototype without linear
ambiguity, the estimated surface normals are also without
linear ambiguity. While this generalized bas-relief
transformation [14][11] is manually removed by Basri
[13] in his 3D reconstruction from surface normals.
Denote the surface of a face by z(x,y), the surface normal
can be rewritten as
n( x, y ) ( p, q,1) ,
where

p

q

nx
| z ( x  1, y )  z ( x, y )
nz
ny

| z ( x, y  1)  z ( x, y ) .
nz


(16)

(17)

Solving the equations by the traditional least squares
method for reconstruction will be every computationally

4.1 Face recognition with three images for each face
Our recognition method is very straightforward by
check the correlation coefficient between the input image
I and the synthetic images, which are from face models in
the database and are synthesized according to the input
illumination conditions.
To synthesize the lighting of the input image, we
minimize the energy function,

( Ha  I ) T ( Ha  I )
(19)
where H [ h1 , h2 ,...hn ] is made of the harmonic
f (a)

images.
In summary, the recognition process has the following
steps.
(1) Modeling the 3D surface normal and albedo for each
face
We are given three aligned face images I1, I2, I3
with nearly frontal, same intensity and non-collinear
*T

lights. Compute the surface normal n with linear
ambiguity and the albedo U for each face model by
equation (3). Align the surface normal to the first one

Proceedings of the Seventh International Conference on Information Visualization (IV‚Äô03)
1093-9547/03 $17.00 ¬© 2003 IEEE

and calculate the average surface normal and albedo
by equation (7), (8), (13), (14). Calculate the
harmonic image H for each face model by (7).
(2) Illumination estimation and image synthesis
Use equation (19) to estimate a for each face
model H and synthesize images according to the
estimated Light a.
(3) Recognition
Employ the na√Øve nearest neighbor classifier with
correlation measurement to the input image and the
synthetic images.
4.2 Face Recognition with One Image for Each Face
In many cases, there is only one frontal-illuminated
image for each face in the database, whereas the task is to
recognize faces under different lighting conditions.
Therefore some famous algorithms, such as the
illumination cone and photometric stereo, can not be
applied and finding ways in these cases still has its
significance.
We assume the face 3D shape is same for all faces.
Therefore by replace the Harmonic image matrix (H) in
subsection 4.1 with an average one, the step of face
recognition with only one image for each face has the
same step as that of in subsection 4.1.

5. Experiments and Discussion
Two kinds of experiments, face recognition and 3D
reconstruction are carried out by face model with 3D
alignment.

5.1 Experiments of Face Recognition
For face recognition, because our aim is to find ways
for dealing with face image variation due only to light
direction changes, we assume that all the face images is
frontal and there is no other variation, except light
direction variation. And all the images used in the
experiment are manually segmented and aligned.
The Yale B database used contains 5760 single light
source images of 10 subjects each seen under 576
viewing conditions (9 poses x 64 illumination
conditions). Because our focus is illumination problem,
only frontal pose is considered and all the 640 images are
manually segmented, rotated and aligned to avoid other
factors, except illumination, to affect the images. And
then we sort these 640 images into 4 sets (Fig. 4)
according to the illumination direction, which is
expressed by azimuth and elevation with respect to the
camera axis. (Note that a positive azimuth implies that the
light source was to the right of the subject while negative

means it was to the left. Positive elevation implies above
the horizon, while negative implies below the horizon.)
Set 1 is composed of 23 images for each subject with
either azimuth or elevation less than 35 degrees. Set 2
contents 16 images for each subject with either azimuth
or elevation less than 65 degrees and more than 35
degrees. And images in Set 3 are made of 13 images for
each subject with either azimuth or elevation more than
65 degrees and less than 95 degrees. Finally, the left
images form the Set 4 with azimuth more than 95
degrees. Figure 4 shows some of the examples of the four
Sets.
It is clear that only in Set 1 the light direction variation
is among the normal range for real application. The light
conditions of images in Set 2, 3 and 4 are so extreme that
most images lose their identities.
To verify the effectiveness of our algorithm, we use
the same classifier for spherical harmonic model
estimated by our algorithm (nine harmonic images and
four harmonic images), direct correlation method and
quotient image [16] method with the bootstrap set in Fig.
6. The classifier used here is the nearest neighbor
classifier, which employs correlation coefficient as the
measurement for classification. The recognition results
shown in Table 1 and Figure 5. It is clear that our
estimated model (nine harmonic images) has almost
perfect recognition rate, which is comparable to that of
the complex illumination cone [12]. Even in the case of
four harmonic images, this model still demonstrates its
robustness for lighting changes in Set 3 and Set 4. The
decreasing of recognition rate from Set 1 to Set 4
indicates that the representation effects deteriorate with
the increasing azimuth or elevation. This result tells us
that neglecting the cast shadow makes the spherical
representation only valid when the azimuth and elevation
is small.
Our recognition results are similar to that of KuangChih Lee [18], but we have a more simple modeling
process.

Proceedings of the Seventh International Conference on Information Visualization (IV‚Äô03)
1093-9547/03 $17.00 ¬© 2003 IEEE

(a) Set 1

(b) Set 2

(c) Set 3

3D reconstruction, our method is more practical for face
images reconstruction.

(d) Set 4
Figure 4 the four image sets used for
recognition
Table 1. Recognition Results
Recognition Rate (%) vs. different sets
Method
Three
images
One
images
Four harmonic
images (three images)
Direction
Correlation
Nine
harmonic
images

Quotient image

Set 1

Set 2

Set 3

Set 4

100

98.1

88.5

74

99.1

89

74

55

87.4

40

43.8

59.2

96.0

70.5

30

19.2

97.0

31.9

5.4

6.7

Figure 7. the 3D surface reconstruction result from
surface normals estimated by 3D alignment

(a) prototype face images

Recognition Rate

Me t h o d s v s . S e t s

10
8
6
4
2

0
0
0
0
0
0
1

2

3

Test Sets

4

N
I
I
N
I
I
F
I
I
D
C

i n
ma
ma
i n
ma
ma
ou
ma
ma
i r
or

e
g
g
e
g
g
r
g
g
e
r

H a r mo n i c
e wi t h T h r e e
es
H a r mo n i c
e s wh i t h O n e
e
H a r mo n i c
e s wi t h T h r e e
es
ct
elati on

(b) its real surface normals by photometric stereo

(c) the unknown light source images
Q o u t i e n t I ma g e

Figure 5. the recognition results

Figure 6. The bootstrap set of quotient image

(d) the estimated surface normals by 3D alignment
Figure 8. the first example of face prototype and
Alignment results.

6.2 Experiments of 3D Face Reconstruction
Figure 7 and Figure 8 show an example of 3D
reconstruction from our estimated surface normals. For
reconstruction, the face model must be aligned by true
surface normals (Figure 8.b). The reconstruction result
(Figure 7) by our estimated surface normals (Figure 8. d)
wiht 3D alignment is excellent compared with most SFS
[17] algorithms, though it can not be compared with the
real 3D face shape.
Though Basri [13] has also described a more general
algorithm for solving linear ambiguity and applied it into

(a) the unknown light source images

(b) the estimated surface normals by 3D alignment

Proceedings of the Seventh International Conference on Information Visualization (IV‚Äô03)
1093-9547/03 $17.00 ¬© 2003 IEEE

[7]

[8]

[9]

(c) 3D surface reconstruction result from surface normals
estimated by 3D alignment
Figure 9. The second example

7. Conclusion and Further Work
In this paper, we introduced a new simple and
practical approach for face modeling. By taking
advantage of the similarity of human faces, this method
makes detour of the linear ambiguity problem by means
of 3D alignment. The recognition and reconstruction
experiments have indicated the effectiveness of the
algorithm.
Though the spherical harmonic function can clearly
derive a theoretical basis for face images under varied
lighting, it ignores the cast shadow, which has great
effects on face images in cases of a large light direction
variation. Therefore in the future, we wish to take the cast
shadow into account by the 3D surface reconstructed
through graphic techniques.

[10]

[11]

[12]

[13]

[14]
[15]

[16]

References
[1] Yael Adnin, Yael Moses and shimon Ullman, ‚ÄúFace
recognition: The problem of compensating for changes in
illumination direction‚Äù, IEEE Transactions on Pattern
Analysis and Machine Intelligence, Vol. 19, No. 7, 1997.
[2] R. J. Woodham, ‚Äú Photometric method for determining
surface orientation from multiple images‚Äù, Optical
engineering‚Äù, Vol. 19, No. 1, pp 139-144,1980
[3] M. Turk, A. Pentland, ‚ÄúEigenface s for recognition‚Äù, J.
Cognitive Neuroscience, Vol. 3, pp. 71-86, 1991.
[4] R. Epstein, P. Hallanan, A. L. Yuille, ‚Äú5¬±2 Eigenimages
Suffice: An Empirical Investigation of Low-Dimensional
Lighting Models‚Äù, IEEE Conf. Workshop on PhysicsBased Vision, pp 108-116, 1995.
[5] P. Hallanan, ‚ÄúA Low-Demensional Representation of
Human Faces for Arbitary Lighting Conditions‚Äù, IEEE
Conf. On Computer Vision and Pattern Recognition, pp
995-99, 1994
[6] A. Yuille, D. Snow, R. Epstein, P. Belhumeur,
‚ÄúDetermining Generative Models of Objects Under
Varying Illumination: Shape and Albedo from Multiple

[17]

[18]

Proceedings of the Seventh International Conference on Information Visualization (IV‚Äô03)
1093-9547/03 $17.00 ¬© 2003 IEEE

Images Using SVD and Integrability, International Journal
of Computer Vision, 35(3), pp203--222, 1999
Ravi Ramamoorthi, Pat Hanrahan, ‚Äú On the relationship
between radiance and irradiance: determining the
illumination from images of a convex Lambertian object‚Äù,
J. Opt. Soc. Am., Vol. 18, No. 10, 2001
Ravi Ramamoorthi, ‚ÄúAnalytic PCA Construction for
Theoretical Analysis of Lighting Variability in Images of a
Lambertian Object‚Äù, IEEE Transactions on Pattern
Analysis and Machine Intelligence, Vol. 24, No. 10, 200210-21
Ronen Brasri, David Jacobs, ‚ÄúLambertian Reflectance and
Linear Subspaces‚Äù, NEC Research Institute Technical
Report 2000-172R
Hallinan, ‚ÄúA Low-Dimensional Representation of Human
Faces for Arbitrary Lighting Conditions‚Äù, Proc. Computer
Vision and Pattern Recognition Conf. pp. 995-999, 1994
H. Hayakawa, ‚Äú Photomertic stereo under alight source
with arbitrary motion‚Äù, J. Opt. Soc. Am. A, Vol. 11, NO.
11, 1994, pp 3079-3089
Athinodoros S. Georghiades and Peter N. Belhumeur,
‚ÄùFrom Few to many: Illumination cone models for face
recognition under variable lighting and pose‚Äù, IEEE
Transactions on Pattern Analysis and Machine Intelligence,
Vol. 23, No. 6, pp 643-660, 2001
Ronen Basri, David Jacobs, ‚ÄúPhotometric Stereo with
General, Unknown Lighting‚Äù, IEEE Conf. On Computer
Vision and Pattern Recognition, Vol. II: 374-381, 2001.
P. N. Belhumeur, David J. Kriegman, A. L. Yuille, ‚Äú The
Bas-Belief Ambiguity‚Äù, CVPR, 1997, pp 1060-1066
R. Epstein, A. L. Yuille and P.N. Bellumeur, ‚Äú Learning
Object Reorientations form Lighting Variation‚Äù, in Object
Rep. in Computer Vision II (J. Ponce, A. Zisserman, and
M. Hebert, eds.), pp.
Amnon Shashua, and Tammy Riklin-Raviv, ‚ÄúThe quotient
image: Class-based re-rendering and recognition with
varying illuminations‚Äù, IEEE Transactions on Pattern
Analysis and Machine Intelligence, Vol. 23, No. 2, pp129139, 2001
Ruo Zhang, Ping-Sing Tsai, James Edwin Cryer, and
Mubarak Shah, ‚ÄúShape from Shading: A Survey‚Äù, IEEE
Transactions on Pattern Analysis and Machine Intelligence,
Vol. 21, No. 8, pp1690-706, 1999
Kuang-Chih Lee, Jeffrey Ho, David Kreigman, ‚ÄúNine
Points of Light: Acquiring Subspaces for Face Recognition
under Varible lighting‚Äù, CVPR 2001

