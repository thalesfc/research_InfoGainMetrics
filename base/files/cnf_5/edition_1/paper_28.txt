2011 Eighth International Conference Computer Graphics, Imaging and Visualization

Keyword annotation of medical image with random forest classifier and confidence
assigning
Ji-Hyeon Lee, Deok-Yeon Kim, ByoungChul Ko, Jae-Yeal Nam
Dept. of Computer Engineering, Keimyung University, 1000 Sindang-dong, Dalseo-gu, Daegu,
704-701, Korea
{sonhyleejh@kmu.ac.kr, kdy3496@kmu.ac.kr, niceko@kmu.ac.kr, jynam@kmu.ac.kr}
classification researches [1-3] have been proposed for
medical image annotation.
Villena-Roman et al. [1] has proved that simple
classification algorithm based on decision table with
weighted relevance aggregation provided similar
classification results against to more complex algorithms
such as nearest-neighbour or boosting.
Setia et al. [2] proposed hierarchical classification
scheme to reduce the computational complexity of the
SVM classifier by using local relational features and
ImageCLEF2006 and 2007 database.
Amaral et al. [3] proposed three different
classification methods, flat, axis-wise, and position-wise
method by modifying SVMs and fused all methods to
improve the annotation results.
To improve the classification and annotation
performance, this study first proposes a novel medical
image classification method combining new local
wavelet-based centre symmetric LBP (WCS-LBP) with
random forests. Second, for semantic keyword based
image retrieval, we propose confidence assigning method
to each annotated keyword by combining probabilities of
random forests with predefined body relation graph.
This study used the ImageCLEF2007 for the
medical annotation and retrieval task. ImageCLEF2007
consists of 10,000 training images and 1,000 test images
from a total of 116 unique classes. The images included
in ImageCLEF are annotated with complete IRMA
(Image Retrieval in Medical Applications) code. The aim
of the radiograph annotation task was to find out how
well current image analysis techniques can identify
image modality, body orientation, body region, and
biological system examined based on the image content
[2]. The IRMA code consists in four independent axes
de-scribing different content within the image [3][4]: the
technical code (T) describes the image modality, the
directional code (D) models body orientations, the
anatomical code (A) refers to the body regions examined,
and the biological code (B) describes the biological
system examined. According the IRMA code, an image
within the ImageCLEF 2007 database has a string of 13
characters, IR-MA:TTTT-DDD-AAA-BBB.

Abstract
This paper introduces an efficient keyword based
medical image retrieval method using image
classification and confidence assigning of each keyword.
To classify images, we first extract wavelet-based CSLBP (WCS-LBP) descriptors from local parts of the
images and then we apply the extracted feature vector to
decision trees to construct random forests, which are an
ensemble of random decision trees. For semantic
annotation based on classification results, we propose
the confidence assigning method to keywords according
to probabilities of random forests with predefined body
relation graph (BRG). After keyword annotation with
different confidence, we proved that our keyword based
image retrieval method showed more efficient retrieval
results compared to equal confidence method.

Keywords---image annotation, random forests,
confidence score, body relation graph

1. Introduction
With the considerable increase digitalized medical
images, Picture Archiving Communication System
(PACS) and Digital Imaging and Communications in
Medicine (DICOM) have attracted the attention of
researchers in the fields of computer networking, image
processing, and database systems. However, these
systems do not support image analysis, and as a
consequence, a large number of medical images are
annotated manually by doctors and medical experts.
Manual annotation is a time consuming and annotation
results are not always reliable because of variable image
quality and human subjectivity. In addition, automatic
keyword annotation is an important step in content-based
image retrieval (CBIR) because CBIR in a massiveimage database without image classification and
annotation is a considerable computational burden
because of the complexity of the operation. Thus, to
overcome the limitations of manual annotation, various
978-0-7695-4484-7/11 $26.00 Â© 2011 IEEE
DOI 10.1109/CGIV.2011.41

156

final class of an input image if p(ci | L) has the
maximum value. The important parameters of RF are the
depth of tree and the number trees, T.

2. Image classification using wavelet-based
centre local binary patterns (WCS-LBP) and
random forests
Because local binary patterns (LBP) [5] describe
gray scale local texture of the image with low
computational complexity by using a simple method, it
has been widely used in various computer vision
applications. In this paper, we extract a local waveletbased centre symmetric LBP (WCS-LBP) [8] rather than
a LBP histogram from all multi-scale sub images,
including low pass filtered sub images, after 2-level
wavelet decomposition. In general, since the X-ray
image has strong edge distribution in the horizontal,
vertical, and diagonal directions, the three high pass
filtered sub images (LH, HL, HH) have important
properties when classifying image categories.
Seven sub-images are extracted after the 2-level
wavelet transform of an image, and all high-pass filtered
sub-images of each level are linearly combined as one

3. keyword annotation using image classification
and Body-Relation-Graph (BRG)
There are three different classification strategies for
annotating the radiographs as follows [2]:
-Flat strategy: an image is classified into one of the
N base classes regardless of IRMA code. This
strategy is usually performed using multi-class
classifiers (e.g. MSVM).
-Axis-wise strategy: according to the IRMA code,
four different multi-class classifiers are trained for
individual Technical, Directional, Anatomical and
Biological axes.
-Binary tree strategy: the classification tree is
generated using agglomerative clustering and the
class-distances. Classification with binary classifier
(e.g. SVM) starts from top, each classification
chooses one of the two possible child nodes until a
leaf node is reached.
In this paper, we use flat and axis-wise method
concurrently: basically we use the flat strategy for image
classification using RF because it is simple and produce
the best results out of the three different classification
strategies as well as it requires N classifiers for N classes
[3]. After RF is trained with training data collected from
each axis, each test image is classified one of total
classes. Then, an image is given the final IRMA code
using the proposed body-relation-graph (BRG) that is the
modification of axis-wise strategy. The BRG is designed
for hierarchical representation of IRMA code. In BRG
structure, BRG is composed of four layers as it was
defined in axis-wise strategy as described in Figure 1 :
one top Technical layer (T), three Anatomical layers (A),
and one Biological layer (B). Especially, A layer is
designed to consider human body parts and their
relations. However Axis-wise strategy should have four
different multi-class classifiers for each individual axis,
e.g. N classifiers for each layer, but, in BRG code, we
need only major 30 classifiers and other 20 classes are
classified according to the hierarchical connection with
the 30 major classes. For example, if one image is
classified class â€˜Fingerâ€™, it is also a member of higher
classes â€˜Handâ€™, â€˜Arm, and Radiography according to the
BRG. Therefore, we can classify 50 classes using only
30 classifiers.
As shown in BRG, the numbers marked in
individual class is used for IRMA â€˜Dâ€™ and â€˜Aâ€™ code and
other codes (T, B) are assigned automatically based on
BRG.

1
2
wavelet energy of level 1, WH and level 2, WH . The
2

low-pass filtered sub-image WLL is used by itself.
In addition, the major problems of X-ray images are
high overlapping between image classes (i.e. hand is
connected with carpal joint), we divide each sub-image
into 4 ÂŸ 4 local grids, and extract 16 dimensional local
wavelet CS-LBPs from each sub-image. The final
histogram for each sub-image is generated by
concatenating the local histograms. Since there are 16
sub-regions, the final dimension of the local WCS-LBP
histogram is 768 [(16 x 3) x16 sub-regions].
For image classification, multi-class support vector
machines (MSVMs) are reasonable choice due to its high
performance and accuracy. However, MSVMs are not
suitable when the feature has high-dimensionality and
the database contains over 1,000 images, due to
computational complexity. Therefore, the high
dimensional local WCS-LBP feature vector with 768
dimensions might make training tasks very time
consuming. In this paper, we have chosen to classify
images using random forests (RF), as proposed by
Breiman [7]. This classifier has been shown to be
effective in a large variety of high dimensional problems,
with high computational performance and accuracy.
In the training procedure, the random forest starts by
choosing a random subset I c from the local WCS-LBP
training data, I . At the node n, the training data I n is
iteratively split into left and right subsets I l and I r by
using the threshold, t, and split function, f (vi ) , for the
feature vector, v.
When classifying the test image, the local WCSLBP histogram of the test image is created over the
whole wavelet transform. The test image is used as input
to the trained RF. The final class distribution is generated
by ensemble (arithmetic averaging) of each distribution
of all trees L = ( l1 , l 2 ,â€¦, lT ) and we choose ci as the

157

After one image is classified one of 30 classes by RF,
all classes which have the link with a classified class are
given the relative distance dis based on the predefined
BRG. The relative distance dis has a simple real number
(disÂ•0) to boost the relative difference between the major
30 classes and the connected higher classes. In this paper,
we set difference of dis between major and linked classes
as 0.8. Therefore, the relative distance of each major
classified class is 0 value and the relative distance of
linked classes are increased plus 0.8 value as apart from
a classified class. For example, if one image is classified
as â€˜nose areaâ€™, dis for â€˜nose areaâ€™ has a 0 value and its
higher node â€˜facial craniumâ€™ has 0.8 value, â€˜craniumâ€™ has
1.6 value, and â€˜radiographyâ€™ has 2.4 value.
After that, the relation weight ( W ) of a classified class i
and its linked parent classes are estimated using
following scaled Fermi function [9];
2
Wi
,J ! 0
1  exp(J Â˜ disi )
(1)

Figure 1: The body-relation-graph (BRG)â€™ for
efficient IRMA code assignment. The number of
box represents class number.

where J ( J ! 0 ) is the control parameter and, we set J
as 0.5.
By using equation (1), major 30 classes have the
relatively larger relation weight (W ) than other classes.
Then, confidence score Cf i of a classified class i is

As shown in Figure 2, if a sample image is classified
into â€˜nose areaâ€™, it has a code â€˜213â€™ for A layer as top
down manner because â€˜nose area (3)â€™ is connected â€˜facial
cranium (1)â€™, â€˜cranium(2)â€™. It also has â€˜400â€™ code for â€˜Dâ€™
because it is a member of â€˜other orientationâ€™. Moreover,
it has â€˜1211â€™ code for T and â€˜700â€™ code for B,
automatically. Therefore, the final code for this image is
â€˜1211-400-213-700â€™ and it has the following keywords
according to the IRMA codes.

estimated by using linear combination of the relation
weight ( W i ) and its final class distribution p(ci | L)
estimated from RF.

Cf i

p (c * )  W i

(2)
From equation (1) and equation (2), 30 keywords of
major 30 classes have the larger confidence scores than
other keywords of higher hierarchical classes. In contrast,
confidence scores for keywords of layer D and layer B
have the half confidence score of the lowest confidence
score of layer A because D and B layer have the lower
priority than A layer because they do not have relative
relations with other classes.
After confidence scores on all connected classes are
estimated, image has the multiple keywords according to
the final IRMA code and all annotated keywords have
different confidence scores based on their hierarchical
relation.

Figure 2: Final TDAB code and each keyword.
Confidence of each keyword is assigned within
a bracket.

5. Experimental results and conclusion
To perform the training, 900 images were randomly
selected from 30 image categories and each class has
equal 30 images. For the test, 1,500 images which did
not use for training were used and each class has equal
50 images. To measure the annotation performance, we
compared the proposed classification method with the
recent widely used MSVM with the same feature by
estimating the error rate and error count.
The error rate means the percentage of codes that
have at least one error in one position within one axis (T,
D, A, B). The error count gives a greater penalty for
misclassification in higher hierarchical instances than for

4. Confidence score assigning
After keyword annotation, an image has the at least
8~10 keywords. However, since all keywords have the
same priority, if the user input a query â€˜Left elbowâ€™, the
retrieval system gives the all images which have the
same keyword according to their sequential order
regardless of their similarity. Therefore, we introduce the
confidence score assigning method by giving the
different priority to keywords by combining probabilities
of RF and distance of BRG.
158

less precise classification in lower hierarchical positions
[3][4].Thus, an image where all positions in all axes are
wrong has an error count of 1, and an image where all
positions in all axes are correct has an error count of 0.
Then error count is normalized by the number of images.
In this paper, because T and B codes are assigned
automatically according to the classification result, we
only evaluated the error rate and error count on D and A
codes. As can be seen from Table 1 to Table 3, the
annotation performance of the MSVM with WCS-LBP
shows 25.5% for Error rate and 0.038 and 0.025 for Error
count. In contrast, the WCS-LBP with RF method
showed 20.3% for Error rate and 0.026 and 0.015 for
Error count, respectively.
The main reason of the good performance of
proposed methods in Error rate and count is that RF was
able to to be effective in a large variety of proposed
high-dimensional WCS-LBP. Moreover, because
MSVMs are not suitable when the feature has highdimensionality and the database contains over 1,000
images, it gave higher error than RF.

References
[1]

[2]

[3]

[4]

[5]

Table 1. Annotation performance on Error rate

[6]

Error rate (%)
20.33%
25.46%

Random Forest
MSVM

[7]
[8]

Table 2. Annotation performance on Error count
of A code

Random Forest
MSVM

[9]

Error count(Anatomical)
0.0259
0.0382

Table 3. Annotation performance on Error count
of D code

Random Forest
MSVM

Error count(Directional)
0.0154
0.0246

In future work, we plan to develop a useful
image retrieval and relevance feedback algorithms
using confidence that can be applied to the contentbased image retrieval system.

Acknowledgements
This work was supported by the grant No. RTI04-01-01
from the Regional Technology Innovation Program of
the Ministry of Knowledge Economy (MKE).

159

J. Villena-RomÃ¡n, J. C. GonzÃ¡lez-CristÃ³bal, J. M. GoÃ±iMenoyo, and J. L. MartÃ­nez-Fernandez. MIRACLEâ€™s
NaÃ¯ve Approach to Medical Images Annotation. In
Working Notes for the CLEF 2005 Workshop Vienna,
Austria, September 2005.
L. Setia, A. Teynor, A. Halawani, and H. Burkhardt.
Grayscale medical image annotation using local
relational features. Pattern Recognition Letters,
29(15):2039â€“2045, May 2008.
I. F. Amaral, F. Coelho, J. F. Costa and J. S. Cardoso.
Hierarchical Medical Image Annotation Using SVMbased Approaches. In IEEE International Conference on
Information Technology and Applications in Biomedicine,
Corfu, Greece, November 2010.
] T. Tommasi, F. Orabona and B. Caputo. An SVM
Confidence-Based Approach to Medical Image
Annotation, Lecture Notes in Computer Science, 5706:
696â€“703, June 1992.
T. Ojala, M. Pietikainen, and T. Maenpaa.
Multiresolution Gray-Scale and Rotation Invariant
Texture Classification with Local Binary Patterns. IEEE
Transactions on Pattern Analysis and Machine
Intelligence, 24(7):971â€“987, July 2002.
M. HeikkilÃ¤, M. PietikÃ¤inen, and C. Schmid. Description
of Interest Regions with Local Binary Patterns. Pattern
Recognition, 42(3):425â€“436, March 2009.
L. Breiman. Random Forests. Machine Leaning, 45(1):5â€“
32, October 2001.

S.H. Kim. X-ray Image Classification using
Random Forests with Local CS-Local Binary
Patterns. Thesis of Graduate School, Keimyung
Univ., December 2010.
Heidemann G. Unsupervised image categorization.
Image and Vision Computing 23: 861-876, 2005.

